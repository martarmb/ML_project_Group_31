{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Group 31** <br>\n",
    "* Ana Margarida Valente, nr 20240936\n",
    "* Eduardo Mendes, nr 20240850\n",
    "* Julia Karpienia, nr 20240514\n",
    "* Marta Boavida, nr 20240519\n",
    "* Victoria Goon, nr 20240550"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "**Table of Contents** <br>\n",
    "* [1. Import](#import)\n",
    "    * [1.1. Import Libraries](#importlibraries)\n",
    "    * [1.2. Import Datasets](#importdatasets)\n",
    "* [2. Data Exploration](#dataexploration)\n",
    "    * [2.1. Data Content and decriptive analysis](#dataanalysis)\n",
    "    * [2.2. Checking incoherencies in the data](#incoherencies)\n",
    "       * [2.2.1 Changing the data types](#types)\n",
    "       * [2.2.2 Checking Duplicates](#duplicates)\n",
    "       * [2.2.3 Checking Unique Values & looking for some values that can indicate missing values](#unique)\n",
    "* [3. Data Visualisation](#visualisation)\n",
    "   * [3.1. Define Metric and Non-Metric Features](#metricandnon)\n",
    "   * [3.2 Metric Features](#metric)\n",
    "   * [3.3 Non-Metric Features](#non)\n",
    "   * [3.4 Target Variable](#33-target-variable)\n",
    "* [4. Data Cleaning and Pre-Processing](#clean)\n",
    "   * [4.1. Missing values in the target variable  - Claim Injury Type](#nantarget)\n",
    "   * [4.2. Missing values in the independent variables](#nanindependent)\n",
    "* [5. Multivariate Analysis](#multi)\n",
    "* [6. Outliers](#outliers)\n",
    "  * [6.1. Visualisation of Outliers](#viewoutliers)\n",
    "  * [6.2. Outlier Removal](#removeoutliers)\n",
    "    * [6.2.1 Manual Outlier Removal](#manual)\n",
    "* [7. Feature Engineering](#feateng)\n",
    "* [8. Data Transformation](#transform)\n",
    "  * [8.1. Feature Encoding](#encode)\n",
    "  * [8.2. Min-max Scaler](#minmax)\n",
    "  * [8.3 Standard Scaler](#std) \n",
    "* [9. Feature Selection](#featselect)\n",
    "  * [9.1. Filter Methods](#filter)\n",
    "    * [9.1.1 Univariate Variables](#uni)\n",
    "    * [9.1.2 Chi-Square](#chi)\n",
    "  * [9.2 Wrapper Methods](#wrapper)\n",
    "    * [9.2.1 RFE](#rfe)\n",
    "  * [9.3 Embedded Methods](#embedded)\n",
    "    * [9.3.1 Lasso Regression](#lasso)\n",
    "  * [9.4 Select K Best Method](#select)\n",
    "  * [9.5 Drop Features According to Feature Selections](#dropfeat)  \n",
    "         \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"import\">\n",
    "    \n",
    "# 1. Import \n",
    "    \n",
    "\n",
    "</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"importlibraries\">\n",
    "\n",
    "### 1.1. Import Libraries\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import standard data processing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "## Import datetime object for date columns in dataset\n",
    "from datetime import datetime\n",
    "\n",
    "## Setting seaborn style\n",
    "sns.set()\n",
    "\n",
    "from math import ceil\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "## Import train_test_split to split data for model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "## Import Libraries for Feature Selection\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "## Import Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Import Cross Validation methods\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_colwidth', None) #Show all columns\n",
    "\n",
    "\n",
    "## Supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"importdatasets\">\n",
    "\n",
    "### 1.2. Import Datasets\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train_data.csv\", low_memory=False)\n",
    "test_data = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"Dataexploration\">\n",
    "    \n",
    "# 2. Data Exploration\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"dataanalysis\">\n",
    "\n",
    "### 2.1. Data content and descriptive analysis\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train data has 3 more variables than test data. We can see below which feature are train, but not in test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Test dataset there is not variables such as: Claim Injury Type (reasonable because it is target variable), Agreement Reached and WCB Decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set \"Claim Identifier\" as the index for the train and test datasets\n",
    "train_data = train_data.set_index(\"Claim Identifier\")\n",
    "test_data = test_data.set_index(\"Claim Identifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"incoherencies\">\n",
    "\n",
    "### 2.2. Checking incoherencies in the data. \n",
    "\n",
    "</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()\n",
    "\n",
    "## DATA TYPES:\n",
    "# Convert accident date (to date type)\n",
    "# convert age (to int)\n",
    "# Alternative dispute resolution (??)\n",
    "# Assembly date (to date type)\n",
    "# birth year (to int)\n",
    "# C2 date (to date type)\n",
    "# C3 date (to date type)\n",
    "# First hearing date (to date)\n",
    "# IME-4 count (to int)\n",
    "# Industry code (object)\n",
    "# OIICS Nature of Injury Description (to object) \n",
    "# WCIO cause of injury code (float to object)\n",
    "# WCIO Nature of Injury Code (float to object)\n",
    "# WCIO Part Of Body Code (float to object)\n",
    "# Agreement reached (??) - boolean/ int(???)\n",
    "# Number of dependents (to int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"types\">\n",
    "\n",
    "#### 2.2.1 Changing the data types\n",
    "\n",
    "</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Age at Injury\"] = train_data[\"Age at Injury\"].astype(\"Int64\")\n",
    "test_data[\"Age at Injury\"] = test_data[\"Age at Injury\"].astype(\"Int64\")\n",
    "\n",
    "train_data[\"Number of Dependents\"] = train_data[\"Number of Dependents\"].astype(\"Int64\")\n",
    "test_data[\"Number of Dependents\"] = test_data[\"Number of Dependents\"].astype(\"Int64\")\n",
    "\n",
    "train_data[\"Birth Year\"] = train_data[\"Birth Year\"].astype(\"Int64\")\n",
    "test_data[\"Birth Year\"] = test_data[\"Birth Year\"].astype(\"Int64\")\n",
    "\n",
    "train_data[\"WCIO Part Of Body Code\"] = train_data[\"WCIO Part Of Body Code\"].astype(\"Int64\")\n",
    "test_data[\"WCIO Part Of Body Code\"] = test_data[\"WCIO Part Of Body Code\"].astype(\"Int64\")\n",
    "\n",
    "train_data[\"WCIO Nature of Injury Code\"] = train_data[\"WCIO Nature of Injury Code\"].astype(\"Int64\")\n",
    "test_data[\"WCIO Nature of Injury Code\"] = test_data[\"WCIO Nature of Injury Code\"].astype(\"Int64\")\n",
    "\n",
    "train_data[\"WCIO Cause of Injury Code\"] = train_data[\"WCIO Cause of Injury Code\"].astype(\"Int64\")\n",
    "test_data[\"WCIO Cause of Injury Code\"] = test_data[\"WCIO Cause of Injury Code\"].astype(\"Int64\")\n",
    "\n",
    "train_data[\"Industry Code\"] = train_data[\"Industry Code\"].astype(\"Int64\")\n",
    "test_data[\"Industry Code\"] = test_data[\"Industry Code\"].astype(\"Int64\")\n",
    "\n",
    "train_data[\"Agreement Reached\"] = train_data[\"Agreement Reached\"].astype(\"Int64\")\n",
    "\n",
    "train_data[\"Accident Date\"] = pd.to_datetime(train_data['Accident Date'])\n",
    "test_data[\"Accident Date\"] = pd.to_datetime(test_data['Accident Date'])\n",
    "\n",
    "train_data[\"Assembly Date\"] = pd.to_datetime(train_data['Assembly Date'])\n",
    "test_data[\"Assembly Date\"] = pd.to_datetime(test_data['Assembly Date'])\n",
    "\n",
    "train_data[\"C-2 Date\"] = pd.to_datetime(train_data['C-2 Date'])\n",
    "test_data[\"C-2 Date\"] = pd.to_datetime(test_data['C-2 Date'])\n",
    "\n",
    "train_data[\"C-3 Date\"] = pd.to_datetime(train_data['C-3 Date'])\n",
    "test_data[\"C-3 Date\"] = pd.to_datetime(test_data['C-3 Date'])\n",
    "\n",
    "train_data[\"First Hearing Date\"] = pd.to_datetime(train_data['First Hearing Date'])\n",
    "test_data[\"First Hearing Date\"] = pd.to_datetime(test_data['First Hearing Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"duplicates\">\n",
    "\n",
    "#### 2.2.2 Checking Duplicates\n",
    "\n",
    "</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter duplicates (keep=False ensures all instances of duplicates are included)\n",
    "duplicates = train_data.loc[train_data.duplicated(keep=False), :]\n",
    "\n",
    "# Sort by all columns to group duplicates together\n",
    "duplicates_sorted = duplicates.sort_values(by=duplicates.columns.tolist())\n",
    "\n",
    "# Display the first 30 rows\n",
    "duplicates_sorted.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter duplicates (keep=False ensures all instances of duplicates are included)\n",
    "duplicates = test_data.loc[test_data.duplicated(keep=False), :]\n",
    "\n",
    "# Sort by all columns to group duplicates together\n",
    "duplicates_sorted = duplicates.sort_values(by=duplicates.columns.tolist())\n",
    "\n",
    "# Display the first 30 rows\n",
    "duplicates_sorted.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_sum_train = train_data.duplicated().sum()\n",
    "duplicates_sum_test = test_data.duplicated().sum()\n",
    "\n",
    "print(f\"There are {duplicates_sum_train} in the training dataset.\")\n",
    "print(f\"There are {duplicates_sum_test} in the test dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not drop duplicates in the test dataset. We only do that in the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"unique\">\n",
    "\n",
    "#### 2.2.3 Checking unique values & looking for some values that can indicate missing values\n",
    "\n",
    "</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in train_data.columns:\n",
    "    unique_values = train_data[column].unique()\n",
    "    unique_values_num = train_data[column].nunique()\n",
    "    print(f\"Unique values in '{column}':\")\n",
    "    print(unique_values)\n",
    "    print(f\"Number of unique values in '{column}':\")\n",
    "    print(unique_values_num)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cells below are commented because they were used to check more detailed unique values for chosen variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['Accident Date'].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['Age at Injury'].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['Assembly Date'].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['Average Weekly Wage'].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['Birth Year'].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['C-2 Date'].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['C-3 Date'].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['Carrier Name'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['Carrier Type'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['First Hearing Date'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['Zip Code'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All listed Variables - unique variables summary \n",
    "\n",
    "1. **Accident Date**: contains dates, no strange values (5539 unique values)\n",
    "\n",
    "2. **Age at Injury**: there are some values >100 and there is age equal to  0  (108 unique values) \n",
    "3. **Alternative Dispute Resolution**: there is one strange unique value such as \"U\" (3 unique values)\n",
    "4. **Assembly Date**: containts dates, no strange values (1096 unique values)\n",
    "5. **Attorney/Representative**: no strange values (2 unique values)\n",
    "6. **Average Weekly Wage**: no typical strange values but there are many records sayin that avg weekly wage is equal to 0, a lot of unique values (120024 unique values)\n",
    "7. **Birth Year**:  one strange values \"0\" (Birth Year cannot be 0) (107 unique values)\n",
    "8. **C-2 Date**: contains data, there are some years from 90s (2475 unique values)\n",
    "9. **C-3 Date**: contains data, there are some years from 90s (1648 unique values)\n",
    "10. **Carrier Name**: there are some strange description such as: '*** CARRIER UNDETERMINED ***', (2046 unique values) \n",
    "11. **Carrier Type**: there is one strange value 'UNKNOWN' (8 unique values)\n",
    "12. **Claim Injury Type**: no strange values (8 unique values)\n",
    "13. **County of Injury**: there is one strange value 'UNKNOWN' (63 unique values)\n",
    "14. **COVID-19 Indicator**: no strange values (2 unique values)\n",
    "15. **District Name**: no strange values (8 unique values)\n",
    "16. **First Hearing Date**: no strange values (1094 unique values)\n",
    "17. **Gender**: two strange values 'U' 'X' (4 unique values)\n",
    "18. **Industry Code**: no strange values (24 unique values)\n",
    "19. **Industry Code Description**: no strange values (20 unique values)\n",
    "20. **Medical Fee Region**: one strange value 'UK' (4 unique values)\n",
    "21. ***OIICS Nature of Injury Description**: variable does not contain any data\n",
    "22. **WCIO Cause of Injury Code**: no strange values (77 unique values) \n",
    "23. **WCIO Cause of Injury Description**: no strange values (74 unique values)\n",
    "24. **WCIO Nature of Injury Code**: and no strange values (56 unique values)\n",
    "25. **WCIO Nature of Injury Description**: no strange values (56 unique values)\n",
    "26. **WCIO Part Of Body Code**: one strange values \"-9\" (57 unique values)\n",
    "27. **WCIO Part Of Body Description**: no strange values (54 unique values)\n",
    "28. **Zip Code**:  this variables is a bit strange, it has some strange zip codes such as zip code '.1605', '00000' or '99999' that does not exist, also it has zip codes that starts with letters not with numbers as well as one unique value 'UNKNO' (8286 unique values)\n",
    "29. **Agreement Reached**:  no strange values (2 unique values)\n",
    "30. **WCB Decision**: no strange values (1 unique value)\n",
    "31. **Number of Dependents**: no strange values (7 unique values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the description above we changed strange values to missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values with NaN\n",
    "\n",
    "train_data['Alternative Dispute Resolution'].replace('U', np.nan, inplace = True)\n",
    "test_data['Alternative Dispute Resolution'].replace('U', np.nan, inplace = True)\n",
    "\n",
    "train_data['Carrier Name'].replace('*** CARRIER UNDETERMINED ***', np.nan, inplace = True)\n",
    "test_data['Carrier Name'].replace('*** CARRIER UNDETERMINED ***', np.nan, inplace = True)\n",
    "\n",
    "train_data['Carrier Type'].replace('UNKNOWN', np.nan, inplace = True)\n",
    "test_data['Carrier Type'].replace('UNKNOWN', np.nan, inplace = True)\n",
    "\n",
    "train_data['County of Injury'].replace('UNKNOWN', np.nan, inplace=True)\n",
    "test_data['County of Injury'].replace('UNKNOWN', np.nan, inplace=True)\n",
    "\n",
    "train_data['Gender'].replace(['X','U'], np.nan, inplace = True)\n",
    "test_data['Gender'].replace(['X','U'], np.nan, inplace = True)\n",
    "\n",
    "train_data['Medical Fee Region'].replace('UK', np.nan, inplace = True)\n",
    "test_data['Medical Fee Region'].replace('UK', np.nan, inplace = True)\n",
    "\n",
    "train_data['Zip Code'].replace([\".1605\", \"00000\", \"99999\",\"UNKNO\"], np.nan, inplace=True)\n",
    "test_data['Zip Code'].replace([\".1605\", \"00000\", \"99999\", \"UNKNO\"], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigating 0 values in the Age variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[train_data['Age at Injury'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age_at_injury_zero = train_data[train_data['Age at Injury'] == 0]\n",
    "# age_at_injury_zero.groupby('Birth Year')['Age at Injury'].value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5463 zeros in total in the variables Age at Injury.\n",
    "- There are 1926 values that are 0 both in Birth Year as well as at Age at Injury \n",
    "- The rest of the zero values (3537) in the variable Age at Injury can be replaced with actual age calulated as accident date - birth year "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing the Age at Injury values that are equal to 0 (where Birth Year is not equal to 0) with the actual age calculated from the difference between the Accident Date and the Birth Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Actual Age'] = train_data['Accident Date'].dt.year - train_data['Birth Year']\n",
    "\n",
    "filtered_rows = train_data[(train_data['Birth Year'] != 0) & (train_data['Age at Injury'] == 0)]\n",
    "\n",
    "train_data.loc[filtered_rows.index, 'Age at Injury'] = train_data['Actual Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Actual Age'] = test_data['Accident Date'].dt.year - test_data['Birth Year']\n",
    "\n",
    "filtered_rows = test_data[(test_data['Birth Year'] != 0) & (test_data['Age at Injury'] == 0)]\n",
    "\n",
    "test_data.loc[filtered_rows.index, 'Age at Injury'] = test_data['Actual Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are any incoherencies in between Age at Injury that is given in the data set and Actual Age calulated as difference between Accident Date and Birth Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Age Diff'] = train_data['Actual Age'] - train_data['Age at Injury']\n",
    "\n",
    "age_difference = train_data[['Accident Date', 'Birth Year','Actual Age', 'Age at Injury', 'Age Diff']]\n",
    "\n",
    "filtered_summary = age_difference[(age_difference['Age Diff'] != 0) &  (age_difference['Birth Year'] != 0) & (age_difference['Birth Year'].notna())]\n",
    "\n",
    "filtered_summary['Age Diff'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Age Diff'] = test_data['Actual Age'] - test_data['Age at Injury']\n",
    "\n",
    "age_difference = test_data[['Accident Date', 'Birth Year','Actual Age', 'Age at Injury', 'Age Diff']]\n",
    "\n",
    "filtered_summary = age_difference[(age_difference['Age Diff'] != 0) &  (age_difference['Birth Year'] != 0) & (age_difference['Birth Year'].notna())]\n",
    "\n",
    "filtered_summary['Age Diff'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no incoherencies in between those two variables. the only unique values are 1 and -1 and that difference can be caused by the fact that we dont have the Birth Month, so Actual Age can be slightly different from the Age Calculated as subtraction of Accident Date and Birth Year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(columns=['Actual Age','Age Diff'], inplace=True)\n",
    "test_data.drop(columns=['Actual Age', 'Age Diff'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['Age at Injury'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[(train_data['Age at Injury'] == 0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.groupby('Age at Injury')['Birth Year'].value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Age at Injury from 0 to missing values where the Birth Year has missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[(train_data['Age at Injury'] == 0) & (train_data['Birth Year'].isna()), 'Age at Injury'] = np.nan\n",
    "test_data.loc[(test_data['Age at Injury'] == 0) & (test_data['Birth Year'].isna()), 'Age at Injury'] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Age at Injury from 0 to missing values where the Birth Year is also 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[(train_data['Age at Injury'] == 0) & (train_data['Birth Year'] == 0), 'Age at Injury'] = np.nan\n",
    "test_data.loc[(test_data['Age at Injury'] == 0) & (test_data['Birth Year'] == 0), 'Age at Injury'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['Age at Injury'].value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point Birth Year variable can be dropped since it has similar info as Age at Injury "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop('Birth Year', axis=1)\n",
    "test_data = test_data.drop('Birth Year', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also strange value (code equal to -9) in the variable WCIO Part Of Body Code. According WCIO website there is no such code as -9. We checked with variable WCIO Part of Body Description which description corresponds to Code -9 in our data set. We found out that -9 is always associated with description \"Multiple\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_train = train_data[train_data[\"WCIO Part Of Body Code\"] == -9]\n",
    "filtered_data_train[\"WCIO Part Of Body Description\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_test = test_data[test_data[\"WCIO Part Of Body Code\"] == -9]\n",
    "filtered_data_test[\"WCIO Part Of Body Description\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We deal with that \"-9\" values after splitting into validation and training set (in the filling missing values section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable ***Zip Code*** has a lot of unique values. Therefore, we decided to group Zip Code based on their first digit of the ZipCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_zip(zip_code):\n",
    "    if pd.isna(zip_code):  \n",
    "        return np.nan \n",
    "    elif isinstance(zip_code, str) and zip_code[0].isdigit():\n",
    "        return zip_code[0]\n",
    "    else:\n",
    "        return \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['zip_code_cat'] = train_data['Zip Code'].apply(categorize_zip)\n",
    "test_data['zip_code_cat'] = test_data['Zip Code'].apply(categorize_zip)\n",
    "\n",
    "train_data['zip_code_cat'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we created zip_code_cat we can drop the variable Zip Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop('Zip Code', axis =1)\n",
    "test_data = test_data.drop('Zip Code', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to drop variables such us: OIICS Nature of Injury Description and WCB Decision. First variable does not containt any values and second one contains only one unique value, so any of them are not informative. We drop WCB Decision only from the train_data because it is not included in the test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =train_data.drop(['OIICS Nature of Injury Description','WCB Decision','Agreement Reached'], axis=1)\n",
    "test_data = test_data.drop(['OIICS Nature of Injury Description'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the description of unique values we can assume that variables such as 'WCIO Part Of Body Description','WCIO Nature of Injury Description','WCIO Cause of Injury Description', 'Carrier Name' could be considered to being dropped, becuase they containts description of coded variables, so we do not need to duplicate the information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recheck for unique values in those variables that have been changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['Alternative Dispute Resolution'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['Carrier Name'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['Carrier Type'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['County of Injury'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['Gender'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['Medical Fee Region'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['Zip Code'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"visualisation\">\n",
    "\n",
    "## 3. Data Visualisation\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"metricandnon\">\n",
    "\n",
    "### 3.1 Define Metric and Non-Metric Features\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing data visualisation we define metric and non-metric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define metric & non-metric features\n",
    "\n",
    "metric_features = [\"Age at Injury\", \"Average Weekly Wage\", \"IME-4 Count\", \"Number of Dependents\"]\n",
    "\n",
    "non_metric_features = [\"Industry Code\", \"WCIO Cause of Injury Code\", \"WCIO Nature of Injury Code\", \"WCIO Part Of Body Code\", \"Accident Date\", \"Alternative Dispute Resolution\",\n",
    "                       \"Assembly Date\", \"Attorney/Representative\", \"C-2 Date\", \"C-3 Date\", \"Carrier Name\", \"Carrier Type\", \"County of Injury\", \"COVID-19 Indicator\",\n",
    "                       \"District Name\", \"First Hearing Date\", \"Gender\", \"Industry Code Description\", \"Medical Fee Region\", \"WCIO Cause of Injury Description\", \n",
    "                       \"WCIO Nature of Injury Description\", \"WCIO Part Of Body Description\",\"zip_code_cat\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"metric\">\n",
    "\n",
    "#### 3.2 Metric Features\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Age at Injury'].plot(\n",
    "    kind='hist',\n",
    "    color='bisque', \n",
    "    edgecolor='black',\n",
    "    bins=19\n",
    ")\n",
    "\n",
    "plt.title('Histogram of Age at Injury')\n",
    "plt.xlabel('Age at Injury')\n",
    "plt.ylabel('Frequency') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of variable Age at Injury:\n",
    "- The data is primarily concentrated between ages 20 and 70, with minimal occurrences beyond age 80. \n",
    "- The age group with the highest frequency of injuries appears to be in the range of 40 to 50, followed closely by the 30-40 and 50-60 ranges.\n",
    "- The histogram is roughly symmetric and bell-shaped, suggesting a somewhat normal distribution centered around middle-aged individuals (30-60).\n",
    "- There are some cases of injuries at extreme ages (under 10 and over 80), though these are rare compared to the central age groups. (Possible outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Average Weekly Wage'].plot(\n",
    "    kind='hist',\n",
    "    color='bisque',\n",
    "    edgecolor='black',\n",
    "    bins=19\n",
    ")\n",
    "\n",
    "plt.title('Histogram of Average Weekly Wage')\n",
    "plt.xlabel('Average Weekly Wage')\n",
    "plt.ylabel('Log10(Frequency)')\n",
    "plt.yscale('log')  \n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of variable Average Weekly Wage:\n",
    "- Most data points are concentrated at the very low end of the wage scale, with a large spike around the minimum wage range. This suggests that the majority of individuals earn a relatively low weekly wage.\n",
    "- The y-axis is in a logarithmic scale, indicating that the actual frequencies vary greatly. This scale allows us to see the distribution more clearly, even though most values are concentrated at the low end.\n",
    "- As wages increase, the frequency decreases rapidly. There are only a few occurrences of higher wages, suggesting that high average weekly wages are rare.\n",
    "- There are small bars at the far right end of the scale (near 2.5 million), which could indicate a few extreme outliers or high-income earners in the dataset. (Possible outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['IME-4 Count'].plot(\n",
    "    kind='hist',\n",
    "    color='bisque', \n",
    "    edgecolor='black',\n",
    "    bins=19\n",
    ")\n",
    "\n",
    "plt.title('Histogram of IME-4 Count')\n",
    "plt.xlabel('IME-4 Count')\n",
    "plt.ylabel('Log10(Frequency)')\n",
    "plt.yscale('log')  \n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of variable IME-4 Count:\n",
    "- The data is heavily skewed towards lower values of IME-4 Count, with the highest frequency occurring between 0 and 10. \n",
    "- The y-axis is in a logarithmic scale, indicating that the actual frequencies vary greatly. This scale allows us to see the distribution more clearly, even though most values are concentrated at the low end.\n",
    "- The frequency decreases as the IME-4 Count increases. There is a gradual decline from low to high values, with only a few occurrences beyond 50.\n",
    "- There is a small bar at the far right (around 70), suggesting a few outliers with unusually high IME-4 Counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Number of Dependents'].plot(\n",
    "    kind='hist',\n",
    "    color='bisque', \n",
    "    edgecolor='black',\n",
    "    bins=5\n",
    ")\n",
    "\n",
    "plt.title('Histogram of Number of Dependents')\n",
    "plt.xlabel('Number of Dependents')\n",
    "plt.ylabel('Frequency') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of variable Number of Dependents:\n",
    "•⁠  ⁠The highest frequencies are at 0 and 6 dependents.\n",
    "•⁠  ⁠There is a noticeable decrease in frequency for categories 2, 3, and 4 dependents, indicating fewer cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_filtered_histogram(data, column_name, min_value, max_value, bins=19):\n",
    "    \n",
    "#     # Filter the data to include only the values in the specified range\n",
    "#     filtered_data = train_data[(train_data[column_name] >= min_value) & (train_data[column_name] <= max_value)][column_name].dropna()\n",
    "    \n",
    "#     #Histogram\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.hist(filtered_data, bins=bins, color='bisque', edgecolor='black')\n",
    "#     plt.title(f'Histogram of {column_name} (range: {min_value} to {max_value})')\n",
    "#     plt.xlabel(column_name)\n",
    "#     plt.ylabel('Frequency')\n",
    "#     plt.grid(axis='y', alpha=0.75)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_filtered_histogram(train_data, column_name=\"Birth Year\", min_value=1920, max_value=2024, bins=19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"non\">\n",
    "\n",
    "#### 3.2 Non-Metric Features\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in non_metric_features:\n",
    "    \n",
    "#     top_categories = train_data[column].value_counts().head(10)\n",
    "\n",
    "#     top_categories_sorted = top_categories.sort_values(ascending=True)\n",
    "\n",
    "#     data_filtered = train_data[train_data[column].isin(top_categories_sorted.index)]\n",
    "    \n",
    "   \n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     sns.countplot(data=data_filtered, \n",
    "#                   x=column, \n",
    "#                   order=top_categories_sorted.index,  \n",
    "#                   palette='tab20b')\n",
    "    \n",
    "  \n",
    "#     plt.xlabel(column, fontsize=14)\n",
    "#     plt.ylabel('Count', fontsize=14)\n",
    "#     plt.title(f'Top 10 Categories in {column}')\n",
    "    \n",
    "    \n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Categorical Variables\n",
    " - **Industry Code**\n",
    "\n",
    "    The top 2 industry codes are **62** (almost 120.000) and **92** (almost 100.000) with a large marge relatively to the rest\n",
    "\n",
    "\n",
    " - **WCIO Cause of Injury Code**\n",
    "\n",
    "   The most common cause of injury has the code **56** (almost 50.000) with a marge relatively to the others\n",
    "\n",
    "\n",
    " - **WCIO Nature of Injury Code** \n",
    "\n",
    "   The top 2 industry codes are **52** (close to 160.000) and **10** (closte to 110.000) with a large marge relatively to the rest\n",
    "\n",
    "\n",
    " - **WCIO Part of Body Code** \n",
    "\n",
    "   The most common causes of injury have the code **42** (slightly exceeds 50.000) and **53** (close to 50.000)\n",
    "\n",
    "\n",
    " - **Accident Date**\n",
    "\n",
    "   01-03-2023 (slightly exceeds 1200) with a large marge relatively to the others\n",
    "\n",
    "\n",
    "- **Alternative Dispute Resolution**\n",
    "\n",
    "   100% = No\n",
    "\n",
    "\n",
    "- **Assembly Date** \n",
    "\n",
    "   Top 3: 06-03-2020 (1400), 11-05-2021 (close to 1400) and 01-04-2022 (slightly exceeds 1200)\n",
    "\n",
    "\n",
    "- **Attorney/Representative**\n",
    "\n",
    "   Almost 400.000 = No\n",
    "\n",
    "\n",
    "- **C-2 Date**\n",
    "\n",
    "   11-05-2021 (close to 1875) with a large marge in relation to the others\n",
    "\n",
    "\n",
    "- **C-3 Date**\n",
    "\n",
    "   Top 3: 21-04-2021, 26-10-2020 and 10-02-2020 (all 3 close to 350)\n",
    "\n",
    "\n",
    "- **Carrier Name** \n",
    "\n",
    "   State Insurance Fund (more than 100.000) with a large marge in relation to the others\n",
    "\n",
    "\n",
    "- **Carrier Type**\n",
    "\n",
    "   1A.Private (almost 300.000) with a large marge in relation to the others\n",
    "\n",
    "\n",
    "- **County of Injury**\n",
    "\n",
    "   Top 3: Suffolk (more than 60.000), Queens (almost 60.000) and Kings (slightly exceeds 50.000)\n",
    "\n",
    "\n",
    "- **COVID-19 Indicator**\n",
    "\n",
    "   No (Close to 550.000)\n",
    "\n",
    "\n",
    "- **District Name**\n",
    "\n",
    "   NYC (slightly exceeds 255.000) with a large marge in relation to the others\n",
    "\n",
    "\n",
    "- **Fisrt Hearing Date**\n",
    "\n",
    "   Top 3: 15-04-2022 (close to 500), 20-01-2022 (slightly exceeds 400) and 15-02-2022 (400)\n",
    "\n",
    "\n",
    "- **Gender** \n",
    "\n",
    "   Male with almost 350.000\n",
    "\n",
    "\n",
    "- **Industry Code Description**\n",
    "\n",
    "   The more frequent are: Health Care and Social Assistance (almost 120.000) and Public Administration (slightly exceeds 90.000) with a large marge in relation to the others\n",
    "\n",
    "\n",
    "- **Medical Fee Region** \n",
    "\n",
    "   IV (close to 275.000) with a large marge in relation to the others\n",
    "\n",
    "\n",
    "- **WCIO Cause os Injury Description**\n",
    "\n",
    "   Top 3: Fellow worker, Patient or Other Person (close to 50.000), Strain or Injury By, NOC (close to 40.000) and Fall, Slip or Trip, NOC (slightly exceeds 30.000)\n",
    "\n",
    "\n",
    "- **WCIO Nature of Injury Description**\n",
    "\n",
    "   Strain or Tear (150.000) and Contusion (slightly exceeds 100.000) with a large marge in relation to the others\n",
    "\n",
    "\n",
    "- **WCIO Part of Body Description**\n",
    "\n",
    "   Top 3: Lower Back Area (close to 50.000), Knee (close to 50.000) and Multiple (slightly exceeds 40.000)\n",
    "\n",
    "\n",
    "- **Zip Code Categorie**\n",
    "\n",
    "   1 (slightly exceeds 500.000) with a large marge in relation to the others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"non\">\n",
    "\n",
    "#### 3.3 Target variable\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claim Injury Type distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(data=train_data,\n",
    "              x='Claim Injury Type',  \n",
    "              palette='tab20b')\n",
    "    \n",
    "  \n",
    "plt.xlabel('Claim Injury Type', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.title('Distribution of Target Variable')\n",
    "    \n",
    "    \n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Target Variable\n",
    "-  ⁠The target variable, \"Claim Injury Type,\" shows a significant class imbalance.\n",
    "-  ⁠The most common category is \"2. NON-COMP\", with around 300.000 cases, which is far more frequent than any other category.\n",
    "- ⁠\"4. TEMPORARY\" and \"3. MED ONLY\" follow as the second and third most common categories, but with notably fewer counts than \"2. NON-COMP\".\n",
    "-  ⁠The categories \"1. CANCELLED\", \"6. PPD NSL\", \"7. PTD\", and \"8. DEATH\" have very few cases, indicating they are rare events in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"clean\">\n",
    "\n",
    "## 4. Data Cleaning and Pre-processing\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"nantarget\">\n",
    "\n",
    "### 4.1 Missing values in the target variable - Claim Injury Type\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Claim Injury Type\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_target = train_data[train_data['Claim Injury Type'].isna()]\n",
    "missing_data_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_target.info()\n",
    "# all features with missing values on the target, are also missing, except Assembly Date -> not relevant (decision -> drop rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= train_data.drop(missing_data_target.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re check for missing values in the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Claim Injury Type'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"nanindependent\">\n",
    "\n",
    "### 4.2 Missing values in the intependent variables\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Before we check for missing values in the independet variables we split our data into training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop('Claim Injury Type', axis = 1)\n",
    "y = train_data['Claim Injury Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size = 0.3, \n",
    "                                                  random_state = 0, \n",
    "                                                  stratify = y, \n",
    "                                                  shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking the number of missing values in each variable in the train and validation set (number and percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_values_train = X_train.isnull().sum().sort_values(ascending=False)\n",
    "# print(missing_values_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_values_val = X_val.isnull().sum().sort_values(ascending=False)\n",
    "# print(missing_values_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentage_train = ((X_train.isnull().sum() / len(X_train)) * 100).sort_values(ascending=False)\n",
    "print(missing_percentage_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentage_val = ((X_val.isnull().sum() / len(X_val)) * 100).sort_values(ascending=False)\n",
    "print(missing_percentage_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentage_test = ((test_data.isnull().sum() / len(test_data)) * 100).sort_values(ascending=False)\n",
    "print(missing_percentage_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables such as ***IME-4 Count*** , ***First Hearing Date*** and ***C-3 Date*** have more than 60% of missing values. \n",
    "<br> In variables ***IME-4 Count*** we assume that missing values states that IME-4 form has not been received. Therefore missing values will be replaced with 0.\n",
    "<br> Missing values in variable ***First Hearing Date*** means that claim has not yet had a hearing held (information provided in dataset description) Thus, it is an information that we want to keep. \n",
    "<br> For missing values in variables ***C-3 Date*** we asume that missing value means that Employee Claim Form has not been received. \n",
    "\n",
    "In the first trial we deleted those three variables since they have a lot of missing values but as we run the model without and got poorly performing model we decided to keep them and we found out that they have significant impact on the target variable and should not be dropped (model performance increased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **IME-4 Count** changing missing values to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[X_train[\"IME-4 Count\"].isna(), \"IME-4 Count\"] = 0\n",
    "X_val.loc[X_val[\"IME-4 Count\"].isna(), \"IME-4 Count\"] = 0\n",
    "test_data.loc[test_data[\"IME-4 Count\"].isna(), \"IME-4 Count\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **First Hearing Date** \n",
    "<br> We decided to change that varibale to binary variable, where NaN values are replaced by 0 - it means that claim has not had a hearing held yet and dataes are replaced by 1 which means that hearing has already been held."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['First Hearing Date Binary'] = X_train['First Hearing Date'].notna().astype(int)\n",
    "X_val['First Hearing Date Binary'] = X_val['First Hearing Date'].notna().astype(int)\n",
    "test_data['First Hearing Date Binary'] = test_data['First Hearing Date'].notna().astype(int)\n",
    "\n",
    "X_train[['First Hearing Date', 'First Hearing Date Binary']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Hearing Data variable can be droped after creating binary variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =X_train.drop(\"First Hearing Date\", axis=1)\n",
    "X_val =X_val.drop(\"First Hearing Date\", axis=1)\n",
    "test_data =test_data.drop(\"First Hearing Date\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_metric_features.remove('First Hearing Date')\n",
    "non_metric_features.append('First Hearing Date Binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **C-2 Date Bin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['C-2 Date Bin'] = X_train['C-2 Date'].notna().astype(int)\n",
    "X_val['C-2 Date Bin'] = X_val['C-2 Date'].notna().astype(int)\n",
    "test_data['C-2 Date Bin'] = test_data['C-2 Date'].notna().astype(int)\n",
    "\n",
    "X_train[['C-2 Date', 'C-2 Date Bin']].head()\n",
    "non_metric_features.append('C-2 Date Bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **C-3 Date** Creating a binary variable from C-3 Date. Changing missing values to 0 and dates to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['C-3 Date Bin'] = X_train['C-3 Date'].notna().astype(int)\n",
    "X_val['C-3 Date Bin'] = X_val['C-3 Date'].notna().astype(int)\n",
    "test_data['C-3 Date Bin'] = test_data['C-3 Date'].notna().astype(int)\n",
    "\n",
    "X_train[['C-3 Date', 'C-3 Date Bin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_metric_features.remove('C-3 Date')\n",
    "non_metric_features.append('C-3 Date Bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =X_train.drop(\"C-3 Date\", axis=1)\n",
    "X_val =X_val.drop(\"C-3 Date\", axis=1)\n",
    "test_data =test_data.drop(\"C-3 Date\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re check for missing percentage in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentage_train = ((X_train.isnull().sum() / len(X_train)) * 100).sort_values(ascending=False)\n",
    "missing_percentage_train = missing_percentage_train[missing_percentage_train > 0]\n",
    "print(missing_percentage_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentage_val = ((X_val.isnull().sum() / len(X_val)) * 100).sort_values(ascending=False)\n",
    "missing_percentage_val = missing_percentage_val[missing_percentage_val > 0]\n",
    "print(missing_percentage_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentage_test = ((test_data.isnull().sum() / len(test_data)) * 100).sort_values(ascending=False)\n",
    "missing_percentage_test = missing_percentage_test[missing_percentage_test > 0]\n",
    "print(missing_percentage_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it was mentioned in the part \"Checking incoherencies in the data\" **WCIO Part of Body Code** has negavite codes such us -9. Each code that is equal to -9 corresponds in the description to Multiple.\n",
    "Acording to WCIO website codes that contains in the description word multiple are: 10, 20, 30, 40, 50, 90, 91. Thus, we decided to fill those values (-9) with mode among codes that corresponds to multiple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid codes for \"Multiple\" according to codes at WCIO website (https://www.guarantysupport.com/wp-content/uploads/2024/02/WCIO-Legacy.pdf)\n",
    "multiple_codes = [10, 20, 30, 40, 50, 90, 91]\n",
    "\n",
    "# Calculate the mode among the valid multiple codes\n",
    "mode_value = X_train[X_train[\"WCIO Part Of Body Code\"].isin(multiple_codes)][\"WCIO Part Of Body Code\"].mode()[0]\n",
    "\n",
    "# Replace only -9 values with the mode (without changing other NaN values)\n",
    "X_train[\"WCIO Part Of Body Code\"] = X_train[\"WCIO Part Of Body Code\"].replace(-9, mode_value)\n",
    "\n",
    "test_data[\"WCIO Part Of Body Code\"] = test_data[\"WCIO Part Of Body Code\"].replace(-9, mode_value)\n",
    "\n",
    "X_val[\"WCIO Part Of Body Code\"] = X_val[\"WCIO Part Of Body Code\"].replace(-9, mode_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All missing values in the variable ***Average Weekly Wage*** are replaced by median "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median_wage = X_train[\"Average Weekly Wage\"].median()\n",
    "# X_train[\"Average Weekly Wage\"].fillna(median_wage, inplace=True)\n",
    "\n",
    "# X_val[\"Average Weekly Wage\"].fillna(median_wage, inplace=True)\n",
    "# test_data[\"Average Weekly Wage\"].fillna(median_wage, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Replacing missing values in variable Age at Injury with mean (That variable is almost normal distributed) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_age = int(X_train[\"Age at Injury\"].mean())\n",
    "\n",
    "# X_train[\"Age at Injury\"].fillna(mean_age, inplace=True)\n",
    "\n",
    "# X_val[\"Age at Injury\"].fillna(mean_age, inplace=True)\n",
    "\n",
    "# test_data[\"Age at Injury\"].fillna(mean_age, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All missing values in the variable ***Average Weekly Wage***  and ***Age at Injury*** are replaced by KNNImputer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_impute = ['Average Weekly Wage', 'Age at Injury']\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "\n",
    "X_train[features_to_impute] = imputer.fit_transform(X_train[features_to_impute])\n",
    "X_val[features_to_impute] = imputer.transform(X_val[features_to_impute])\n",
    "test_data[features_to_impute] = imputer.transform(test_data[features_to_impute])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Categorical variables that missing values should be replaced with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns that missing values should be replaced with mode\n",
    "mode_variables = [\n",
    "    'Medical Fee Region',\n",
    "    'zip_code_cat',\n",
    "    'WCIO Part Of Body Code',\n",
    "    'WCIO Part Of Body Description',\n",
    "    'WCIO Nature of Injury Code',\n",
    "    'WCIO Nature of Injury Description',\n",
    "    'WCIO Cause of Injury Description',\n",
    "    'WCIO Cause of Injury Code',\n",
    "    'C-2 Date',\n",
    "    'Industry Code',\n",
    "    'Industry Code Description',\n",
    "    'Gender',\n",
    "    'Accident Date',\n",
    "    'Carrier Type',\n",
    "    'Carrier Name',\n",
    "    'County of Injury',\n",
    "    'Alternative Dispute Resolution'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in mode_variables:\n",
    "    mode_value = X_train[column].mode()\n",
    "    if not mode_value.empty:\n",
    "        X_train[column] = X_train[column].fillna(mode_value[0])\n",
    "        X_val[column] = X_val[column].fillna(mode_value[0])  \n",
    "        test_data[column] = test_data[column].fillna(mode_value[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re check for number of  missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After analysis we also decided to drop variables that contain descriptions of other coded variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop_desc = ['WCIO Part Of Body Description','WCIO Nature of Injury Description','WCIO Cause of Injury Description', 'Carrier Name', 'Industry Code Description']\n",
    "\n",
    "X_train =X_train.drop(columns_to_drop_desc, axis=1)\n",
    "X_val = X_val.drop(columns_to_drop_desc, axis=1)\n",
    "test_data =test_data.drop(columns_to_drop_desc, axis=1)\n",
    "\n",
    "non_metric_features = [feature for feature in non_metric_features if feature not in columns_to_drop_desc]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"multi\">\n",
    "\n",
    "## 5. Multivariate Analysis\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cross tabular \n",
    "cross = pd.crosstab(X_train[\"Attorney/Representative\"], X_train['First Hearing Date Binary'], normalize=True).round(2)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data=cross, annot=True, \n",
    "            vmin=0, vmax=1, center=0,\n",
    "            square=True, linewidths=.5,\n",
    "            cmap='PiYG')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 5% of folks who had a \"First Hearing Date\" did NOT have an attorney and 9% had an attorney but no hearing date. These situations are a little unusual but not strange. Not having an attorney when there is no hearing date is expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking below, the distribution of \"Claim Injury Types\" is quite even throughout, whereas the distribution for when data for the \"First Hearing Date\" wasn't available. \"Non-Comp\" seems to be the predominate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = X_train.groupby([X_train[\"First Hearing Date Binary\"], y_train]).size().unstack()\n",
    "cat_df.plot.bar(stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the following histogram  for when an attonrey/representative is present or not, for when an attonrey/representative isn't present, the values seem more imbalanced with supports the initial hypothesis that if an attorney is involved, the claim injury being compensated is less likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = X_train.groupby([X_train[\"Attorney/Representative\"], y_train]).size().unstack()\n",
    "cat_df.plot.bar(stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare \"Attorney/Representative\" vs \"First Hearing Date Binary\" for when there is no attorney and there is no first hearing date. The wide imbalance shows that this could be a particular variable relationship that could help with deciding Claim Injury Type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attorney_data = X_train[ (X_train[\"Attorney/Representative\"] == \"N\")]\n",
    "cat_df = attorney_data.groupby([X_train[\"First Hearing Date Binary\"], y_train]).size().unstack()\n",
    "cat_df.plot.bar(stacked=True)\n",
    "plt.title(\"First Hearing Date Distribution when No Attorney is Present\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare \"Attorney/Representative\" vs \"First Hearing Date Binary\" for when there is an attorney. Compared to the last histogram, this one's values are more balanced. This further concludes that the presence of an attorney helps with the distribution of Claim injury Type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attorney_data = X_train[ (X_train[\"Attorney/Representative\"] == \"Y\")]\n",
    "cat_df = attorney_data.groupby([X_train[\"First Hearing Date Binary\"], y_train]).size().unstack()\n",
    "cat_df.plot.bar(stacked=True)\n",
    "plt.title(\"First Hearing Date Distribution when an Attorney is Present\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an attorney isn't needed, the \"Alternative Distribution Resolution\" could play a part in deciding the Claim Injury Type. Let's examine the dsitribution of \"Claim Injury Type\" and \"Alternative Dispute Resolution\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = X_train.groupby([X_train[\"Alternative Dispute Resolution\"], y_train]).size().unstack()\n",
    "cat_df.plot.bar(stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are barely any instances where Alternative Distribution is \"Y\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.groupby(\"Alternative Dispute Resolution\")[\"Alternative Dispute Resolution\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With there being only 34 values where the resolution is \"Y\", the possibility that it helped with desicions is low. <br/> <br/>\n",
    "Whereas the distribution for Attorney/Representative is much higher (as seen below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.groupby(\"Attorney/Representative\")[\"Attorney/Representative\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = X_train.groupby([X_train[\"Medical Fee Region\"], y_train]).size().unstack()\n",
    "cat_df.plot.bar(stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = X_train.groupby([X_train[\"Carrier Type\"], y_train]).size().unstack()\n",
    "cat_df.plot.bar(stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross = pd.crosstab(X_train[\"Medical Fee Region\"], X_train['Carrier Type'], normalize=True).round(2)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data=cross, annot=True, \n",
    "            vmin=0, vmax=1, center=0,\n",
    "            square=True, linewidths=.5,\n",
    "            cmap='PiYG')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = X_train.groupby([X_train[\"Age at Injury\"], y_train]).size().unstack()\n",
    "cat_df.plot.bar(stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be an even distribution between claim injury types and gender. (Probably won't play much of a role in deciding claim type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = X_train.groupby([X_train[\"Gender\"], y_train]).size().unstack()\n",
    "cat_df.plot.bar(stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predominatley male dataset - most likely due to the nature of work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs outlier fixes\n",
    "catpc_df = X_train.groupby([\"Age at Injury\", 'Gender'])['Gender'].size().unstack()\n",
    "catpc_df.plot.bar(stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predomintantly using zip codes based in category 1. This includes NY, Delaware, and Pennsylvania. Given that the organization is for the state of New York, it makes sense that a majority of the variables will be based in the zipcode category that New York belongs to. Using District Name will be more useful. This is potentially ground to remove the zipcode columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = X_train.groupby([X_train['zip_code_cat'], y_train]).size().unstack()\n",
    "cat_df.plot.bar(stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = X_train.groupby([X_train['District Name'], y_train]).size().unstack()\n",
    "cat_df.plot.bar(stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentage of \"Non-comp\" injury types in NYC is well above the rest of the districts. Potentially high ocurances of fraud in big cities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross = pd.crosstab(X_train['District Name'], y_train, normalize=True).round(2)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data=cross, annot=True, \n",
    "            vmin=0, vmax=1, center=0,\n",
    "            square=True, linewidths=.5,\n",
    "            cmap='PiYG')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = X_train.groupby([X_train['COVID-19 Indicator'], y_train]).size().unstack()\n",
    "cat_df.plot.bar(stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a closer look at when the COVID Indicator is \"Y\". <br/>\n",
    "<br/>\n",
    "It seems whenever covid is present, the chance that it will be marked as \"Non-comp\" is higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data = X_train[ X_train[\"COVID-19 Indicator\"] == \"Y\"]\n",
    "cat_df = covid_data.groupby([X_train['COVID-19 Indicator'], y_train]).size().unstack()\n",
    "cat_df.plot.bar(stacked=True)\n",
    "plt.title(\"Claim Injry Distribution when COVID-19 is marked\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs outlier fixes\n",
    "sns.set_style('ticks')\n",
    "fig, ax = plt.subplots()\n",
    "hb = ax.hexbin(X_train[\"Age at Injury\"], X_train[\"Average Weekly Wage\"], gridsize=20)\n",
    "ax.set_title(\"Hexagon binning for age and income\")\n",
    "cb = fig.colorbar(hb, ax=ax, label='counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of claim types on the number dependants is distributed evenly implying number of dependents have no weight on the claim injury type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = X_train.groupby([X_train[\"Number of Dependents\"], y_train]).size().unstack()\n",
    "cat_df.plot.bar(stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = X_train.groupby([X_train[\"WCIO Nature of Injury Code\"], y_train]).size().unstack()\n",
    "cat_df.plot.bar(stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = X_train.groupby([X_train[\"WCIO Part Of Body Code\"], y_train]).size().unstack()\n",
    "cat_df.plot.bar(stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = X_train.groupby([X_train[\"WCIO Cause of Injury Code\"], y_train]).size().unstack()\n",
    "cat_df.plot.bar(stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical variables to plot\n",
    "independent_var = ['Age at Injury','Alternative Dispute Resolution',\n",
    "       'Attorney/Representative', 'Carrier Type', \n",
    "       'County of Injury', 'COVID-19 Indicator', 'District Name', 'Gender',\n",
    "       'Industry Code', 'Medical Fee Region', 'WCIO Cause of Injury Code',\n",
    "       'WCIO Nature of Injury Code', 'WCIO Part Of Body Code',  'Number of Dependents', \n",
    "       'zip_code_cat']\n",
    "# Add more variables to independent_var as needed\n",
    "\n",
    "# Target variable (for example purposes)\n",
    "target_variable = \"Claim Injury Type\"\n",
    "\n",
    "# Loop through each variable and plot a stacked bar chart\n",
    "for var in independent_var:\n",
    "    # Group by the current variable and target, then unstack to get counts in a DataFrame\n",
    "    catpc_df = train_data.groupby([var, target_variable])[target_variable].size().unstack()\n",
    "    \n",
    "    # Plot stacked bar chart\n",
    "    catpc_df.plot(kind='bar', stacked=True, figsize=(10, 6), colormap=\"tab20\")\n",
    "    \n",
    "    # Add title and labels\n",
    "    plt.title(f\"Stacked Bar Plot of {var} by {target_variable}\")\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel(\"Count\")\n",
    "    \n",
    "    # Display plot\n",
    "    plt.tight_layout()  # Adjust layout to fit titles and labels\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"outliers\">\n",
    "\n",
    "## 6. Outliers\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"viewoutliers\">\n",
    "\n",
    "### 6.1 Visualisation of Outliers\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by plotting some box plots to see the behaviour of the dataset on the metric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ALL Numeric Variables' Histograms in one figure\n",
    "\n",
    "sp_rows = 2\n",
    "sp_cols = ceil(len(metric_features) / sp_rows)\n",
    "\n",
    "\n",
    "# Create individual axes where each histogram will be placed\n",
    "fig, axes = plt.subplots(sp_rows, \n",
    "                         sp_cols, \n",
    "                         figsize=(10, 6),\n",
    "                         tight_layout=True\n",
    "                        )\n",
    "\n",
    "# Plot data\n",
    "# Iterate across axes objects and associate each histogram:\n",
    "for ax, feat in zip(axes.flatten(), metric_features): # Notice the zip() function and flatten() method\n",
    "    sns.boxplot(x=X_train[feat], ax=ax)\n",
    "    \n",
    "# Add a centered title to the figure:\n",
    "title = \"Numeric Variables' Box Plots\"\n",
    "\n",
    "plt.suptitle(title)\n",
    "\n",
    "if not os.path.exists(os.path.join('..', 'figures', 'eda')):\n",
    "    # if the eda directory is not present then create it first\n",
    "    os.makedirs(os.path.join('..', 'figures', 'eda'))\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join('..', 'figures', 'eda', 'numeric_variables_boxplots.png'), dpi=200)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the numeric variables' box plot all in one figure\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
    "fig.suptitle(\"Numeric Variables' Box Plots\", fontsize=16)\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "# Define colors for each plot\n",
    "colors = sns.color_palette(\"pastel\")\n",
    "\n",
    "# Creating box plots with improvements\n",
    "sns.boxplot(data=X_train, x='Age at Injury', ax=axes[0, 0], color=colors[0])\n",
    "sns.boxplot(data=X_train, x='Average Weekly Wage', ax=axes[0, 1], color=colors[1])             # Log scale example\n",
    "sns.boxplot(data=X_train, x='IME-4 Count', ax=axes[1, 0], color=colors[2])\n",
    "sns.boxplot(data=X_train, x='Number of Dependents', ax=axes[1, 1], color=colors[4])\n",
    "\n",
    "# Rotate x-axis labels if needed\n",
    "for ax in axes.flat:\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"removeoutliers\">\n",
    "\n",
    "### 6.2 Outlier Removal\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start by computing the interquartile range\n",
    "q1 = train_data[metric_features].quantile(0.25)\n",
    "q3 = train_data[metric_features].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "#Now we are going to compute the limits:\n",
    "lower_lim = q1 - (1.5 * iqr)\n",
    "upper_lim = q3 + (1.5 * iqr)\n",
    "\n",
    "for feature in metric_features:\n",
    "    print(f\"{feature:<25}  Lower Limit: {lower_lim[feature]:>10}      Upper Limit: {upper_lim[feature]:>10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's detect 'obvious' outliers, those where every characteristic in outside the interquartile range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_outliers(train_data, metric_features, lower_lim, upper_lim):\n",
    "    outliers = {}\n",
    "    obvious_outliers = []\n",
    "\n",
    "    for metric in metric_features:\n",
    "        if metric not in train_data.columns:\n",
    "            continue\n",
    "        \n",
    "        if metric not in lower_lim or metric not in upper_lim:\n",
    "            continue\n",
    "        \n",
    "        outliers[metric] = []\n",
    "        llim = lower_lim[metric]\n",
    "        ulim = upper_lim[metric]\n",
    "        \n",
    "        for i, value in enumerate(train_data[metric]):\n",
    "            if pd.isna(value):\n",
    "                continue\n",
    "            \n",
    "            if value < llim or value > ulim:\n",
    "                outliers[metric].append(value)\n",
    "        \n",
    "        print(f\"Total outliers in {metric}: {len(outliers[metric])}\")\n",
    "\n",
    "    # Check for observations that are outliers in all features (Obvious Outliers)\n",
    "    for index, row in train_data.iterrows():\n",
    "        is_global_outlier = True\n",
    "        for metric in metric_features:\n",
    "            if metric not in train_data.columns or metric not in lower_lim or metric not in upper_lim:\n",
    "                is_global_outlier = False\n",
    "                break\n",
    "            \n",
    "            value = row[metric]\n",
    "            if pd.isna(value):\n",
    "                is_global_outlier = False\n",
    "                break\n",
    "            \n",
    "            llim = lower_lim[metric]\n",
    "            ulim = upper_lim[metric]\n",
    "            \n",
    "            if llim <= value <= ulim:\n",
    "                is_global_outlier = False\n",
    "                break\n",
    "        \n",
    "        if is_global_outlier:\n",
    "            obvious_outliers.append(index)\n",
    "    print(\"-----------------------------\")\n",
    "    print(f\"Total global outliers: {len(obvious_outliers)}\")\n",
    "    return outliers, obvious_outliers\n",
    "    \n",
    "    \n",
    "outliers, obvious_outliers = identify_outliers(X_train, metric_features, lower_lim, upper_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could see, there is no observation that has every characteristic outside the interquartile range, since there is no outlier in 'Number of Dependents'.\n",
    "But let's try this program again but without that feature, to see if there is any observation only with outliers, except on this feature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_features_test =[\"Age at Injury\", \"Average Weekly Wage\", \"IME-4 Count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers, obvious_outliers = identify_outliers(X_train, metric_features_test, lower_lim, upper_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we conclude that there aren't any obvious outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a filter that will verify if an observation has every characteristic in the Interquartile Range or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_iqr = []                                            \n",
    "for metric in metric_features:\n",
    "    llim = lower_lim[metric]\n",
    "    ulim = upper_lim[metric]\n",
    "    filters_iqr.append(X_train[metric].between(llim, ulim, inclusive='neither'))\n",
    "\n",
    "filters_iqr_all = pd.concat(filters_iqr, axis=1).all(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_iqr_all  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train[X_train[filters_iqr_all] == 'False'])      #These are the features that have at least one of its characteristics considered as an outlier (out of the IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_iqr = X_train[filters_iqr_all]\n",
    "print('Percentage of data kept after removing outliers:', 100*(np.round(X_train_iqr.shape[0] / X_train.shape[0], decimals=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to be sure about the outliers, let's try another method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"manuall\">\n",
    "\n",
    "#### 6.2.1 Manual Outlier Removal\n",
    "</a>"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_manual1 = (\n",
    "                (X_train[\"Age at Injury\"] <= 90)\n",
    "                &\n",
    "                (X_train[\"Average Weekly Wage\"] <= 0.2*1e6)\n",
    "                &\n",
    "                (X_train[\"IME-4 Count\"] < 10)                            \n",
    "                #&\n",
    "                #(X_train[\"Number of Dependents\"])                        #There are no outliers here, so I think there is no manual restriction to make\n",
    ")\n",
    "X_train_out_man = X_train[filters_manual1]\n",
    "filtered_indices = X_train_out_man.index\n",
    "y_train = y_train.loc[filtered_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of data kept after removing outliers:', 100*(np.round(X_train_out_man.shape[0] / X_train.shape[0], decimals=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_out = X_train[(filters_iqr_all | filters_manual1)]            #Only if the 2 filter says that the observation are outliers we remove!\n",
    "filtered_indices = X_train_out.index\n",
    "y_train = y_train.loc[filtered_indices]\n",
    "\n",
    "print('Percentage of data kept after removing outliers:', 100*np.round(X_train_out.shape[0] / X_train.shape[0], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporary dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_preprocessed_df = pd.concat([X_train_out, y_train], axis=1)\n",
    "# train_preprocessed_df.to_csv(\"train_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_preprocessed_df = pd.concat([X_val, y_val], axis=1)\n",
    "# validation_preprocessed_df.to_csv(\"validation_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data.to_csv(\"test_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv(\"train_preprocessed.csv\", low_memory=False)\n",
    "# validation_data = pd.read_csv(\"validation_preprocessed.csv\", low_memory=False)\n",
    "# test_data = pd.read_csv(\"test_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = train_data.set_index(\"Claim Identifier\")\n",
    "# validation_data = validation_data.set_index(\"Claim Identifier\")\n",
    "# test_data = test_data.set_index(\"Claim Identifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_out = train_data.drop('Claim Injury Type', axis = 1)\n",
    "# y_train = train_data['Claim Injury Type']\n",
    "\n",
    "# X_val = validation_data.drop('Claim Injury Type', axis = 1)\n",
    "# y_val = validation_data['Claim Injury Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"feateng\">\n",
    "\n",
    "## 7. Feature Engineering\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During our previous steps we have already created vairables such as:\n",
    "- zip_code_cat \n",
    "- C-3 Date Bin\n",
    "- C-2 Date Bin\n",
    "- First Hearing Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another variables that have been created:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_out.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creating new feature Days Between Accident_Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_out[\"Days Between Accident_Assembly\"] = (X_train_out['Assembly Date'] - X_train_out['Accident Date']).dt.days\n",
    "negative_count = (X_train_out[\"Days Between Accident_Assembly\"] < 0).sum()\n",
    "\n",
    "print(\"Number of rows with negative values in 'Days Between Accident_Assembly':\", negative_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val[\"Days Between Accident_Assembly\"] = (X_val['Assembly Date'] - X_val['Accident Date']).dt.days\n",
    "negative_count = (X_val[\"Days Between Accident_Assembly\"] < 0).sum()\n",
    "\n",
    "print(\"Number of rows with negative values in 'Days Between Accident_Assembly' in validation set:\", negative_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"Days Between Accident_Assembly\"] = (test_data['Assembly Date'] - test_data['Accident Date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_features.append(\"Days Between Accident_Assembly\")\n",
    "non_metric_features.remove(\"Assembly Date\")\n",
    "non_metric_features.remove(\"Accident Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creating new feature Days Between Accident_C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_out[\"Days Between Accident_C2\"] = (X_train_out['C-2 Date'] - X_train_out['Accident Date']).dt.days\n",
    "negative_count = (X_train_out[\"Days Between Accident_C2\"] < 0).sum()\n",
    "\n",
    "print(\"Number of rows with negative values in 'Days Between Accident_C2' in train set:\", negative_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val[\"Days Between Accident_C2\"] = (X_val['C-2 Date'] - X_val['Accident Date']).dt.days\n",
    "negative_count = (X_val[\"Days Between Accident_C2\"] < 0).sum()\n",
    "\n",
    "print(\"Number of rows with negative values in 'Days Between Accident_C2' in validation set:\", negative_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"Days Between Accident_C2\"] = (test_data['C-2 Date'] - test_data['Accident Date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_features.append(\"Days Between Accident_C2\")\n",
    "non_metric_features.remove(\"C-2 Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating feature Season_of_Accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to map month to season\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'Fall'\n",
    "\n",
    "\n",
    "X_train_out['Season_of_Accident'] = X_train_out['Accident Date'].dt.month.apply(get_season)\n",
    "X_val['Season_of_Accident'] = X_val['Accident Date'].dt.month.apply(get_season)\n",
    "test_data['Season_of_Accident'] = test_data['Accident Date'].dt.month.apply(get_season)\n",
    "\n",
    "# Checking new feature \n",
    "print(X_train_out[['Accident Date', 'Season_of_Accident']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_metric_features.append(\"Season_of_Accident\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Season of Accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_counts = X_train_out['Season_of_Accident'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=season_counts.index, y=season_counts.values)\n",
    "plt.title(\"Accident Frequency by Season\", fontsize=16)\n",
    "plt.xlabel(\"Season\", fontsize=14)\n",
    "plt.ylabel(\"Number of Accidents\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creating feature Age_Group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 25, 35, 45, 55, 65, np.inf]\n",
    "labels = ['0-25', '26-35', '36-45', '46-55', '56-65', '65+']\n",
    "\n",
    "X_train_out['Age_Group'] = pd.cut(X_train_out['Age at Injury'], bins=bins, labels=labels)\n",
    "X_val['Age_Group'] = pd.cut(X_val['Age at Injury'], bins=bins, labels=labels)\n",
    "test_data['Age_Group'] = pd.cut(test_data['Age at Injury'], bins=bins, labels=labels)\n",
    "\n",
    "print(X_train_out[['Age at Injury', 'Age_Group']].head())\n",
    "non_metric_features.append(\"Age_Group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group_counts = X_train_out['Age_Group'].value_counts()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=age_group_counts.index, y=age_group_counts.values)\n",
    "plt.title(\"Frequency of Age Groups at Injury\", fontsize=16)\n",
    "plt.xlabel(\"Age Group\", fontsize=14)\n",
    "plt.ylabel(\"Number of Accidents\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to the website: https://www.guarantysupport.com/wp-content/uploads/2024/02/WCIO-Legacy.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creating feature WCIO Part of Body_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_body_code(code):\n",
    "    if 10 <= code <= 19:\n",
    "        return 'Head'\n",
    "    elif 20 <= code <= 29:\n",
    "        return 'Neck'\n",
    "    elif 30 <= code <= 39:\n",
    "        return 'Upper Extremities'\n",
    "    elif 40 <= code <= 49:\n",
    "        return 'Trunk'\n",
    "    elif 50 <= code <= 59:\n",
    "        return 'Lower Extremities'\n",
    "    elif code in [64, 65, 66, 90, 91, 99]:\n",
    "        return 'Multiple Body Parts'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "\n",
    "X_train_out['WCIO Part of Body_cat'] = X_train_out['WCIO Part Of Body Code'].apply(categorize_body_code) # Corrected the column name\n",
    "X_val['WCIO Part of Body_cat'] = X_val['WCIO Part Of Body Code'].apply(categorize_body_code)\n",
    "test_data['WCIO Part of Body_cat'] = test_data['WCIO Part Of Body Code'].apply(categorize_body_code)\n",
    "non_metric_features.append(\"WCIO Part of Body_cat\")\n",
    "\n",
    "print(X_train_out[['WCIO Part of Body_cat', 'WCIO Part Of Body Code']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing newly created variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_category_counts = X_train_out['WCIO Part of Body_cat'].value_counts() # Corrected the column name\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=body_category_counts.index, y=body_category_counts.values, palette=\"viridis\")\n",
    "plt.title(\"Frequency of WCIO Part of Body Categories\", fontsize=16)\n",
    "plt.xlabel(\"Body Part Category\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create feature WCIO Nature of Injury Code_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_nature_of_injury(code):\n",
    "    if  1<= code <= 59:\n",
    "        return 'Specific Injury'\n",
    "    elif 60 <= code <= 80:\n",
    "        return 'Occupational Disease or Cumulative Injury'\n",
    "    else:\n",
    "        return 'Multiple Injuries'\n",
    "  \n",
    "\n",
    "X_train_out['WCIO Nature of Injury Code_cat'] = X_train_out['WCIO Nature of Injury Code'].apply(categorize_nature_of_injury)\n",
    "X_val['WCIO Nature of Injury Code_cat'] = X_val['WCIO Nature of Injury Code'].apply(categorize_nature_of_injury)\n",
    "test_data['WCIO Nature of Injury Code_cat'] = test_data['WCIO Nature of Injury Code'].apply(categorize_nature_of_injury)\n",
    "non_metric_features.append('WCIO Nature of Injury Code_cat')\n",
    "\n",
    "print(X_train_out[['WCIO Nature of Injury Code_cat', 'WCIO Nature of Injury Code']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing newly created variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nature_of_injury_category_counts = X_train_out['WCIO Nature of Injury Code_cat'].value_counts()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=nature_of_injury_category_counts.index, y=nature_of_injury_category_counts.values, palette=\"viridis\")\n",
    "plt.title(\"Frequency of WCIO Nature of Injury Categories\", fontsize=16)\n",
    "plt.xlabel(\"Nature of Injury Category\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create feature WCIO Cause of Injury Code_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_cause_of_injury(code):\n",
    "    if  code in [1, 2, 3, 4, 5, 6,7,8,9,11,14,84]:\n",
    "        return 'Burn or Scald'\n",
    "    elif code in [10,12,13,20]:\n",
    "        return 'Caught In, Under of Between'\n",
    "    elif 15<= code <= 19:\n",
    "        return 'Cut, Puncture, Scrape Injured By'\n",
    "    elif 25<= code <= 33:\n",
    "        return 'Fall, Slip or Trip Injury'\n",
    "    elif code in [40,41,45,46,47,48,50]:\n",
    "        return 'Motor Vehicle'\n",
    "    elif code in [52,53,54,55,56,57,58,59,60,61,97]:\n",
    "        return 'Strain or Injury By'\n",
    "    elif 65 <= code <= 70:\n",
    "        return 'Striking Against or Stepping On'\n",
    "    elif code in [74,75,76,77,78,79,80,81,85,86]:\n",
    "        return 'Struck or Injured By'\n",
    "    elif code in [94,95]:\n",
    "        return 'Rubbed or Abraded By'\n",
    "    else: \n",
    "        return 'Miscellaneous Causes'\n",
    "\n",
    "X_train_out['WCIO Cause of Injury_cat'] = X_train_out['WCIO Cause of Injury Code'].apply(categorize_cause_of_injury)\n",
    "X_val['WCIO Cause of Injury_cat'] = X_val['WCIO Cause of Injury Code'].apply(categorize_cause_of_injury)\n",
    "test_data['WCIO Cause of Injury_cat'] = test_data['WCIO Cause of Injury Code'].apply(categorize_cause_of_injury)\n",
    "non_metric_features.append('WCIO Cause of Injury_cat')\n",
    "\n",
    "print(X_train_out[['WCIO Cause of Injury_cat', 'WCIO Cause of Injury Code']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing newly created variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_of_injury_category_counts = X_train_out['WCIO Cause of Injury_cat'].value_counts()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=cause_of_injury_category_counts.index, y=cause_of_injury_category_counts.values, palette=\"viridis\")\n",
    "plt.title(\"Frequency of WCIO Cause of Injury  Categories\", fontsize=16)\n",
    "plt.xlabel(\"Cause of Injury Category\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create feature Age at Assembly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this variable has to be developed more\n",
    "# X_train_out['Age_at_Assembly'] = pd.to_datetime(X_train_out['Assembly Date']).dt.year - X_train_out['Age at Injury']\n",
    "# X_val['Age_at_Assembly'] = pd.to_datetime(X_val['Assembly Date']).dt.year - X_val['Age at Injury']\n",
    "# train_data['Age_at_Assembly'] = pd.to_datetime(train_data['Assembly Date']).dt.year - train_data['Age at Injury']\n",
    "\n",
    "# print(X_train[['Age at Injury', 'Age_at_Assembly']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ensure the 'Accident Date' and 'Assembly Date' are in datetime format\n",
    "# X_train_out['Accident Date'] = pd.to_datetime(X_train_out['Accident Date'])\n",
    "# X_train_out['Assembly Date'] = pd.to_datetime(X_train_out['Assembly Date'])\n",
    "# X_val['Accident Date'] = pd.to_datetime(X_val['Accident Date'])\n",
    "# X_val['Assembly Date'] = pd.to_datetime(X_val['Assembly Date'])\n",
    "# test_data['Accident Date'] = pd.to_datetime(test_data['Accident Date'])\n",
    "# test_data['Assembly Date'] = pd.to_datetime(test_data['Assembly Date'])\n",
    "\n",
    "# # Calculate Age at Assembly by subtracting the 'Accident Date' year from the 'Assembly Date' year\n",
    "# X_train_out['Age_at_Assembly'] = (X_train_out['Assembly Date'].dt.year - X_train_out['Accident Date'].dt.year) + X_train_out['Age at Injury']\n",
    "# X_val['Age_at_Assembly'] = (X_val['Assembly Date'].dt.year - X_val['Accident Date'].dt.year) + X_val['Age at Injury']\n",
    "# test_data['Age_at_Assembly'] = (test_data['Assembly Date'].dt.year - test_data['Accident Date'].dt.year) + test_data['Age at Injury']\n",
    "\n",
    "# # Print to verify\n",
    "# print(X_train_out[['Age at Injury', 'Accident Date', 'Assembly Date', 'Age_at_Assembly']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins = [0, 25, 35, 45, 55, 65, np.inf]\n",
    "# labels = ['18-25', '26-35', '36-45', '46-55', '56-65', '65+']\n",
    "\n",
    "# X_train_out['Age_at_Assembly_bins'] = pd.cut(X_train_out['Age_at_Assembly'], bins=bins, labels=labels)\n",
    "# X_val['Age_at_Assembly_bins'] = pd.cut(X_val['Age_at_Assembly'], bins=bins, labels=labels)\n",
    "# test_data['Age_at_Assembly_bins'] = pd.cut(test_data['Age_at_Assembly'], bins=bins, labels=labels)\n",
    "\n",
    "# print(X_train_out[['Age_at_Assembly_bins', 'Age_at_Assembly']].head())\n",
    "# non_metric_features.append(\"Age_at_Assembly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age_group_counts = X_train_out['Age_at_Assembly_bins'].value_counts()\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.barplot(x=age_group_counts.index, y=age_group_counts.values)\n",
    "# plt.title(\"Frequency of Age Groups at Assembly\", fontsize=16)\n",
    "# plt.xlabel(\"Age Group\", fontsize=14)\n",
    "# plt.ylabel(\"Number of Accidents\", fontsize=14)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Average Weekly Wage by Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_out['Industry_Avg_Weekly_Wage'] = X_train_out.groupby('Industry Code')['Average Weekly Wage'].transform('mean')\n",
    "X_val['Industry_Avg_Weekly_Wage'] = X_val.groupby('Industry Code')['Average Weekly Wage'].transform('mean')\n",
    "test_data['Industry_Avg_Weekly_Wage'] = test_data.groupby('Industry Code')['Average Weekly Wage'].transform('mean')\n",
    "metric_features.append('Industry_Avg_Weekly_Wage')\n",
    "\n",
    "print(X_train_out[['Industry_Avg_Weekly_Wage', 'Industry Code']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting average weekly wage by industry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "industry_avg_wage = X_train_out.groupby('Industry Code')['Industry_Avg_Weekly_Wage'].mean()\n",
    "\n",
    "sns.barplot(x=industry_avg_wage.index, y=industry_avg_wage.values, palette=\"viridis\")\n",
    "\n",
    "\n",
    "plt.title(\"Average Weekly Wage by Industry\", fontsize=16)\n",
    "plt.xlabel(\"Industry Code\", fontsize=14)\n",
    "plt.ylabel(\"Average Weekly Wage\", fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_drop = ['C-2 Date', 'Accident Date','Assembly Date']\n",
    "X_train_out = X_train_out.drop(variables_to_drop, axis = 1)\n",
    "X_val = X_val.drop(variables_to_drop, axis = 1)\n",
    "test_data = test_data.drop(variables_to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_metric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_out.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finding negative values in Metric columns and fixing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train with values in [Days Between Accident_Assembly] that are negative: \" + str(len(X_train_out[ X_train_out[\"Days Between Accident_Assembly\"] < 0])) + \".\")\n",
    "print(\"X_val with values in [Days Between Accident_Assembly] that are negative: \" + str(len(X_val[ X_val[\"Days Between Accident_Assembly\"] < 0])) + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train with values in [Days Between Accident_C2] that are negative: \" + str(len(X_train_out[ X_train_out[\"Days Between Accident_C2\"] < 0])) + \".\")\n",
    "print(\"X_val with values in [Days Between Accident_C2] that are negative: \" + str(len(X_val[ X_val[\"Days Between Accident_C2\"] < 0])) + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train with values in [Age at Injury] that are negative: \" + str(len(X_train_out[ X_train_out[\"Age at Injury\"] < 0])) + \".\")\n",
    "print(\"X_val with values in [Age at Injury] that are negative: \" + str(len(X_val[ X_val[\"Age at Injury\"] < 0])) + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[ X_train[\"Days Between Accident_Assembly\"] < 0][\"Days Between Accident_Assembly\"] = 0\n",
    "X_train_out[\"Days Between Accident_Assembly\"] = X_train_out[\"Days Between Accident_Assembly\"].clip(lower=0)\n",
    "X_val[\"Days Between Accident_Assembly\"] = X_val[\"Days Between Accident_Assembly\"].clip(lower=0)\n",
    "test_data[\"Days Between Accident_Assembly\"] = test_data[\"Days Between Accident_Assembly\"].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_out[\"Days Between Accident_C2\"] = X_train_out[\"Days Between Accident_C2\"].clip(lower=0)\n",
    "X_val[\"Days Between Accident_C2\"] = X_val[\"Days Between Accident_C2\"].clip(lower=0)\n",
    "test_data[\"Days Between Accident_C2\"] = test_data[\"Days Between Accident_C2\"].clip(lower=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"transform\">\n",
    "\n",
    "## 8. Data Transformation - Encoding and Scaling \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Use spearman correlation \n",
    "corr = X_train_out[metric_features].corr(method=\"spearman\").round(3)\n",
    "\n",
    "# Plot heatmap\n",
    "sns.heatmap(data=corr, annot=True, \n",
    "            # fmt='s',\n",
    "            vmin=-1, vmax=1, center=0,\n",
    "            square=True, linewidths=.5,\n",
    "            cmap='PiYG')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_metric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val[non_metric_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_out[non_metric_features].head()\n",
    "# 'WCIO Nature of Injury Code_cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[non_metric_features].head()\n",
    "#'WCIO Cause of Injury_cat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"encode\">\n",
    "\n",
    "### 8.1 Feature Encoding\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoder for target variable (training and validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate Label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#Fit the encoder on the training target variable\n",
    "Y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "#Transform the training and validation target variable\n",
    "Y_val_encoded = label_encoder.transform(y_val)\n",
    "\n",
    "#Convert the results back to DataFrames\n",
    "Y_train_encoded_df = pd.DataFrame(Y_train_encoded, columns=['encoded_target'], index=pd.Series(y_train.index))\n",
    "Y_val_encoded_df = pd.DataFrame(Y_val_encoded, columns=['encoded_target'], index=pd.Series(y_val.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_encoded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoder for dependent variables (non-metric): (only for training and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy = X_train_out.copy()\n",
    "X_val_copy = X_val.copy()\n",
    "test_data_copy = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_val.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different encoding strategy - One hot encoder, label encoder, frequency encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_features_to_encode = [\"Carrier Type\", \"County of Injury\", \"District Name\", \"Medical Fee Region\", \"zip_code_cat\", \"Season_of_Accident\", \"Age_Group\", 'WCIO Part of Body_cat', 'WCIO Nature of Injury Code_cat', 'WCIO Cause of Injury_cat']\n",
    "label_encoder_features = [\"Alternative Dispute Resolution\", \"Attorney/Representative\", \"COVID-19 Indicator\", \"Gender\"]\n",
    "frequency_encoder_features = [\"Industry Code\", \"WCIO Cause of Injury Code\", \"WCIO Nature of Injury Code\", \"WCIO Part Of Body Code\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ONE HOT ENCODER for low cardinality features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the encoder with the chosen settings\n",
    "# ohc = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "\n",
    "# # Fit the encoder on the training set only\n",
    "# ohc.fit(X_train_copy[oh_features_to_encode])  \n",
    "\n",
    "# # Transform the training set\n",
    "# ohc_train_features = ohc.transform(X_train_copy[oh_features_to_encode])\n",
    "# ohc_train_df = pd.DataFrame(ohc_train_features, index=X_train_copy.index, columns=ohc.get_feature_names_out(oh_features_to_encode))\n",
    "\n",
    "# # Concatenate the encoded features back to the training set\n",
    "# X_train_encoded = pd.concat([X_train_copy.drop(columns=oh_features_to_encode), ohc_train_df], axis=1)\n",
    "\n",
    "# # Transform the validation set using the same encoder (do not fit again)\n",
    "# ohc_val_features = ohc.transform(X_val_copy[oh_features_to_encode])\n",
    "# ohc_val_df = pd.DataFrame(ohc_val_features, index=X_val_copy.index, columns=ohc.get_feature_names_out(oh_features_to_encode))\n",
    "\n",
    "# # Concatenate the encoded features back to the validation set\n",
    "# X_val_encoded = pd.concat([X_val_copy.drop(columns=oh_features_to_encode), ohc_val_df], axis=1)\n",
    "\n",
    "# # Transform the test set using the same encoder (do not fit again)\n",
    "# ohc_test_features = ohc.transform(test_data_copy[oh_features_to_encode])\n",
    "# ohc_test_df = pd.DataFrame(ohc_test_features, index=test_data_copy.index, columns=ohc.get_feature_names_out(oh_features_to_encode))\n",
    "\n",
    "# # Concatenate the encoded features back to the test set\n",
    "# test_data_encoded = pd.concat([test_data_copy.drop(columns=oh_features_to_encode), ohc_test_df], axis=1)\n",
    "\n",
    "# # Final datasets : X_train_encoded, X_val_encoded, test_data_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Label encoder for binary features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Standardize the data to ensure consistent types and no unexpected whitespace\n",
    "# X_train_copy[label_encoder_features] = X_train_copy[label_encoder_features].astype(str).apply(lambda x: x.str.strip())\n",
    "# X_val_copy[label_encoder_features] = X_val_copy[label_encoder_features].astype(str).apply(lambda x: x.str.strip())\n",
    "# test_data_copy[label_encoder_features] = test_data_copy[label_encoder_features].astype(str).apply(lambda x: x.str.strip())\n",
    "\n",
    "# # Initialize a dictionary to store encoders for each feature\n",
    "# label_encoders = {}\n",
    "\n",
    "# # Encode the features\n",
    "# for feature in label_encoder_features:\n",
    "#     # Initialize a LabelEncoder for this feature\n",
    "#     le = LabelEncoder()\n",
    "    \n",
    "#     # Fit the LabelEncoder on the training data for this feature\n",
    "#     le.fit(X_train_copy[feature])\n",
    "    \n",
    "#     # Store the encoder for future use\n",
    "#     label_encoders[feature] = le\n",
    "\n",
    "#     # Transform the feature in all datasets (train, validation, test)\n",
    "#     X_train_copy[feature] = le.transform(X_train_copy[feature])\n",
    "#     X_val_copy[feature] = le.transform(X_val_copy[feature])\n",
    "#     test_data_copy[feature] = le.transform(test_data_copy[feature])\n",
    "\n",
    "# #Final datasets = X_train_copy, X_val_copy, test_data_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Frequency encoder for codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a dictionary to store frequency mappings for each feature\n",
    "# frequency_encoders = {}\n",
    "\n",
    "# # Apply Frequency Encoding\n",
    "# for feature in frequency_encoder_features:\n",
    "#     # Calculate frequency counts on the training data\n",
    "#     freq_counts = X_train_copy[feature].value_counts(normalize=True)\n",
    "    \n",
    "#     # Store the frequency mapping for future reference\n",
    "#     frequency_encoders[feature] = freq_counts\n",
    "\n",
    "#     # Map the frequencies to the training set\n",
    "#     X_train_copy[feature] = X_train_copy[feature].map(freq_counts)\n",
    "    \n",
    "#     # Map the frequencies to the validation set (using the training frequencies)\n",
    "#     X_val_copy[feature] = X_val_copy[feature].map(freq_counts)\n",
    "    \n",
    "#     # Map the frequencies to the test set (using the training frequencies)\n",
    "#     test_data_copy[feature] = test_data_copy[feature].map(freq_counts)\n",
    "\n",
    "# # Final datasets:\n",
    "# # - X_train_copy, X_val_copy, test_data_copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_add = label_encoder_features + frequency_encoder_features\n",
    "\n",
    "# X_train_encoded = X_train_encoded.drop(columns=columns_to_add)\n",
    "# X_train_encoded = pd.concat([X_train_encoded, X_train_copy[columns_to_add]], axis=1)\n",
    "\n",
    "# X_val_encoded = X_val_encoded.drop(columns=columns_to_add)\n",
    "# X_val_encoded = pd.concat([X_val_encoded, X_val_copy[columns_to_add]], axis=1)\n",
    "\n",
    "# test_data_encoded = test_data_encoded.drop(columns=columns_to_add)\n",
    "# test_data_encoded = pd.concat([test_data_encoded, test_data_copy[columns_to_add]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded.describe(include=\"all\").round(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_encoded.describe(include=\"all\").round(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_encoded.describe(include=\"all\").round(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - One hot encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the encoder with the chosen settings\n",
    "ohc = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "\n",
    "# Fit the encoder on the training set only\n",
    "ohc.fit(X_train_copy[non_metric_features])  \n",
    "\n",
    "# Transform the training set\n",
    "ohc_train_features = ohc.transform(X_train_copy[non_metric_features])\n",
    "ohc_train_df = pd.DataFrame(ohc_train_features, index=X_train_copy.index, columns=ohc.get_feature_names_out(non_metric_features))\n",
    "\n",
    "# Concatenate the encoded features back to the training set\n",
    "X_train_encoded = pd.concat([X_train_copy.drop(columns=non_metric_features), ohc_train_df], axis=1)\n",
    "\n",
    "# Transform the validation set using the same encoder (do not fit again)\n",
    "ohc_val_features = ohc.transform(X_val_copy[non_metric_features])\n",
    "ohc_val_df = pd.DataFrame(ohc_val_features, index= X_val_copy.index, columns=ohc.get_feature_names_out(non_metric_features))\n",
    "\n",
    "# Concatenate the encoded features back to the validation set\n",
    "X_val_encoded = pd.concat([X_val_copy.drop(columns=non_metric_features), ohc_val_df], axis=1)\n",
    "\n",
    "# Transform the test set using the same encoder (do not fit again)\n",
    "ohc_test_features = ohc.transform(test_data_copy[non_metric_features])\n",
    "ohc_test_df = pd.DataFrame(ohc_test_features, index= test_data_copy.index, columns=ohc.get_feature_names_out(non_metric_features))\n",
    "\n",
    "# Concatenate the encoded features back to the test set\n",
    "test_data_encoded = pd.concat([test_data_copy.drop(columns=non_metric_features), ohc_test_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"minmax\">\n",
    "\n",
    "### 8.2 Min-max Scaler\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min-max scaler for dependent variables (metric):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_out[metric_features].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MinMaxScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the training set and transform the training features\n",
    "scaled_feat = scaler.fit_transform(X_train_copy[metric_features])\n",
    "\n",
    "# Convert the scaled features back to a DataFrame \n",
    "scaled_feat_df = pd.DataFrame(scaled_feat, columns=metric_features, index=X_train_copy.index)\n",
    "\n",
    "# Concatenate the scaled features back to the original DataFrames\n",
    "X_train_min_max_scaled = pd.concat([X_train_copy.drop(columns=metric_features), scaled_feat_df], axis=1)\n",
    "X_train_min_max_scaled_encoded = pd.concat([X_train_encoded.drop(columns=metric_features), scaled_feat_df], axis=1)\n",
    "\n",
    "# Transform the validation set using the same scaler (do not fit again)\n",
    "scaled_feat = scaler.transform(X_val_copy[metric_features])\n",
    "\n",
    "# Convert the scaled features back to a DataFrame \n",
    "scaled_feat_df = pd.DataFrame(scaled_feat, columns=metric_features, index=X_val_copy.index)\n",
    "\n",
    "# Concatenate the scaled features back to the original DataFrames\n",
    "X_val_min_max_scaled = pd.concat([X_val_copy.drop(columns=metric_features), scaled_feat_df], axis=1)\n",
    "X_val_min_max_scaled_encoded = pd.concat([X_val_encoded.drop(columns=metric_features), scaled_feat_df], axis=1)\n",
    "\n",
    "# Transform the test set using the same scaler (do not fit again)\n",
    "scaled_feat = scaler.transform(test_data_copy[metric_features])\n",
    "\n",
    "# Convert the scaled features back to a DataFrame \n",
    "scaled_feat_df = pd.DataFrame(scaled_feat, columns=metric_features, index=test_data_copy.index)\n",
    "\n",
    "# Concatenate the scaled features back to the original DataFrames\n",
    "test_min_max_scaled = pd.concat([test_data_copy.drop(columns=metric_features), scaled_feat_df], axis=1)\n",
    "test_min_max_scaled_encoded = pd.concat([test_data_encoded.drop(columns=metric_features), scaled_feat_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_min_max_scaled[metric_features].describe().round(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_min_max_scaled[metric_features].describe().round(2).T\n",
    "# Days between accident assembly & days between accident C2 have min values != from zero!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_min_max_scaled[metric_features].describe().round(2).T\n",
    "# avg weekly wage max value very different from 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"std\">\n",
    "\n",
    "### 8.3 Standard Scaler\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard scaler for dependent variables (metric):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a StandardScaler instance\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "#Fit the scaler on the training set and transform the training features\n",
    "standard_scaled_feat = standard_scaler.fit_transform(X_train_copy[metric_features])\n",
    "\n",
    "#Convert the scaled features back to a DataFrame for better usability\n",
    "standard_scaled_feat_df = pd.DataFrame(standard_scaled_feat, columns=metric_features, index=X_train_copy.index)\n",
    "\n",
    "#Concatenate the scaled features back to the original DataFrames\n",
    "X_train_std_scaler = pd.concat([X_train_copy.drop(columns=metric_features), standard_scaled_feat_df], axis=1)\n",
    "X_train_std_scaler_encoded = pd.concat([X_train_encoded.drop(columns=metric_features), standard_scaled_feat_df], axis=1)\n",
    "\n",
    "#Transform the validation set using the same scaler (do not fit again)\n",
    "standard_scaled_feat = standard_scaler.transform(X_val_copy[metric_features])\n",
    "\n",
    "#Convert the scaled features back to a DataFrame for better usability\n",
    "standard_scaled_feat_df = pd.DataFrame(standard_scaled_feat, columns=metric_features, index=X_val_copy.index)\n",
    "\n",
    "#Concatenate the scaled features back to the original DataFrames\n",
    "X_val_std_scaler = pd.concat([X_val_copy.drop(columns=metric_features), standard_scaled_feat_df], axis=1)\n",
    "X_val_std_scaler_encoded = pd.concat([X_val_encoded.drop(columns=metric_features), standard_scaled_feat_df], axis=1)\n",
    "\n",
    "#Transform the validation set using the same scaler (do not fit again)\n",
    "standard_scaled_feat = standard_scaler.transform(test_data_copy[metric_features])\n",
    "\n",
    "#Convert the scaled features back to a DataFrame for better usability\n",
    "standard_scaled_feat_df = pd.DataFrame(standard_scaled_feat, columns=metric_features, index=test_data_copy.index)\n",
    "\n",
    "#Concatenate the scaled features back to the original DataFrames\n",
    "test_std_scaler = pd.concat([test_data_copy.drop(columns=metric_features), standard_scaled_feat_df], axis=1)\n",
    "# X_val_std_scaler = pd.concat([X_val_encoded.drop(columns=metric_features), standard_scaled_feat_df], axis=1)\n",
    "X_test_std_scaler_encoded = pd.concat([test_data_encoded.drop(columns=metric_features), standard_scaled_feat_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std_scaler[metric_features].describe().round(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_std_scaler[metric_features].describe().round(2).T\n",
    "# avg weekly wage std dev very different from 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_std_scaler[metric_features].describe().round(2).T\n",
    "# avg weekly wage std dev very different from 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std_scaler_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_std_scaler_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_std_scaler_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std_scaler_encoded.describe(include=\"all\").round(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Comparing the macro F1 score for both scaling methods, we concluded that the Standard Scaler performed better, so we decided to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"featselect\">\n",
    "\n",
    "## 9. Feature Selection\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"filter\">\n",
    "\n",
    "### 9.1 Filter Methods\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"uni\">\n",
    "\n",
    "### 9.1.1 Univariate Variables\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_features_ = [col for col in metric_features if col in X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[metric_features_].var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since neither of the variables are univariate (variance=0), we will not dicard any of the variables based on this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"chi\">\n",
    "\n",
    "### 9.1.2 Chi-Square\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chi-Square test is a statistical test used to determine if there is a significant association between two categorical variables.\n",
    "\n",
    "A high Chi-Square value and a low p-value indicate that the variables are likely dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features=X_train_out[non_metric_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define a function that will test whether a categorical independent variable (var) is an important predictor for the target using the Chi-Square test of independence.\n",
    "\n",
    "    It prints whether the variable is important or not for prediction based on the Chi-Square test.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestIndependence(X,y,var,alpha=0.05):\n",
    "    #Create a contingency table to observe the relationship between the target variable y and the feature X \n",
    "    dfObserved = pd.crosstab(y,X) \n",
    "    #Perform the Chi-Square test of independence on the contingency table\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(dfObserved.values)\n",
    "    #Create a DataFrame for the expected values from the Chi-Square test\n",
    "    dfExpected = pd.DataFrame(expected, columns=dfObserved.columns, index = dfObserved.index)\n",
    "    #Check if the p-value is smaller than the alpha level\n",
    "    if p<alpha:\n",
    "        result=\"{0} is IMPORTANT for Prediction\".format(var)\n",
    "    else:\n",
    "        result=\"{0} is NOT an important predictor. (Discard {0} from model)\".format(var)\n",
    "    print(result,f\", p-value = {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the function throughout the categorical variables\n",
    "for var in cat_features:\n",
    "    TestIndependence(cat_features[var],y_train, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Chi-Square test we conclude that all categorical features are important for prediction, and so, we will not dicard any of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cramer\">\n",
    "\n",
    "### 9.1.3 Cramér's V\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cramér's V is a statistical measure used to assess the strength of association between two categorical variables. \n",
    "\n",
    "Provides a value between 0 and 1.\n",
    "\n",
    "**Cramér's V values:**\n",
    "\n",
    "- 0 to 0.1: Weak or insignificant association.\n",
    "- 0.1 to 0.3: Moderate association.\n",
    "- 0.3 to 0.5: Strong association.\n",
    "- Above 0.5: Very strong association (potentially redundant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def cramers_v(x, y):\n",
    "    \n",
    "    contingency_table = pd.crosstab(x, y)\n",
    "\n",
    "    chi2, _, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "    n = contingency_table.sum().sum()\n",
    "\n",
    "    k = min(contingency_table.shape)\n",
    "\n",
    "    v = np.sqrt(chi2 / (n * (k - 1)))\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_metric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns of single codes, use the variables with categories\n",
    "X_train_encoded=X_train_encoded.drop(columns=['WCIO Cause of Injury Code_7.035564779962712e-05',\n",
    "       'WCIO Cause of Injury Code_7.538105121388619e-05',\n",
    "       'WCIO Cause of Injury Code_8.79445597495339e-05',\n",
    "       'WCIO Cause of Injury Code_9.296996316379297e-05',\n",
    "       'WCIO Cause of Injury Code_0.00013819859389212468',\n",
    "       'WCIO Cause of Injury Code_0.0002085542416917518',\n",
    "       'WCIO Cause of Injury Code_0.00023619396047017675',\n",
    "       'WCIO Cause of Injury Code_0.00026132097754147214',\n",
    "       'WCIO Cause of Injury Code_0.0002638336792486017',\n",
    "       'WCIO Cause of Injury Code_0.00036182904582665376',\n",
    "       'WCIO Cause of Injury Code_0.00045731171069757627',\n",
    "       'WCIO Cause of Injury Code_0.0004950022363045194',\n",
    "       'WCIO Cause of Injury Code_0.000693505671167753',\n",
    "       'WCIO Cause of Injury Code_0.0007563232138459915',\n",
    "       'WCIO Cause of Injury Code_0.0007940137394529346',\n",
    "       'WCIO Cause of Injury Code_0.0008241661599384891',\n",
    "       'WCIO Cause of Injury Code_0.000917136123102282',\n",
    "       'WCIO Cause of Injury Code_0.000944775841880707',\n",
    "       'WCIO Cause of Injury Code_0.0010829744357728317',\n",
    "       'WCIO Cause of Injury Code_0.0011935333108865315',\n",
    "       'WCIO Cause of Injury Code_0.0012488127484433812',\n",
    "       'WCIO Cause of Injury Code_0.0017061244591409575',\n",
    "       'WCIO Cause of Injury Code_0.001987547050339466',\n",
    "       'WCIO Cause of Injury Code_0.0022790204483664925',\n",
    "       'WCIO Cause of Injury Code_0.00234686339445899',\n",
    "       'WCIO Cause of Injury Code_0.0024498841644513014',\n",
    "       'WCIO Cause of Injury Code_0.0025503922327364827',\n",
    "       'WCIO Cause of Injury Code_0.0031710295543974794',\n",
    "       'WCIO Cause of Injury Code_0.0032313343953685883',\n",
    "       'WCIO Cause of Injury Code_0.0035027061797385786',\n",
    "       'WCIO Cause of Injury Code_0.004213800762856238',\n",
    "       'WCIO Cause of Injury Code_0.004457532828447804',\n",
    "       'WCIO Cause of Injury Code_0.004786696752081774',\n",
    "       'WCIO Cause of Injury Code_0.005073144746694541',\n",
    "       'WCIO Cause of Injury Code_0.005171140113272593',\n",
    "       'WCIO Cause of Injury Code_0.005646040735920076',\n",
    "       'WCIO Cause of Injury Code_0.005653578841041465',\n",
    "       'WCIO Cause of Injury Code_0.005706345576891185',\n",
    "       'WCIO Cause of Injury Code_0.00578926473322646',\n",
    "       'WCIO Cause of Injury Code_0.0064526179839086584',\n",
    "       'WCIO Cause of Injury Code_0.006829523239978089',\n",
    "       'WCIO Cause of Injury Code_0.006917467799727623',\n",
    "       'WCIO Cause of Injury Code_0.007651176698209449',\n",
    "       'WCIO Cause of Injury Code_0.007794400695515832',\n",
    "       'WCIO Cause of Injury Code_0.008000442235500454',\n",
    "       'WCIO Cause of Injury Code_0.00835222047449859',\n",
    "       'WCIO Cause of Injury Code_0.008616054153747192',\n",
    "       'WCIO Cause of Injury Code_0.008751740045932188',\n",
    "       'WCIO Cause of Injury Code_0.010942815934549146',\n",
    "       'WCIO Cause of Injury Code_0.01147048329304635',\n",
    "       'WCIO Cause of Injury Code_0.01255848313223344',\n",
    "       'WCIO Cause of Injury Code_0.013171582348773048',\n",
    "       'WCIO Cause of Injury Code_0.013307268240958042',\n",
    "       'WCIO Cause of Injury Code_0.013887702335304966',\n",
    "       'WCIO Cause of Injury Code_0.017284875043344104',\n",
    "       'WCIO Cause of Injury Code_0.017654242194292145',\n",
    "       'WCIO Cause of Injury Code_0.017827618612084085',\n",
    "       'WCIO Cause of Injury Code_0.018958334380292378',\n",
    "       'WCIO Cause of Injury Code_0.019805114855595034',\n",
    "       'WCIO Cause of Injury Code_0.020332782214092238',\n",
    "       'WCIO Cause of Injury Code_0.02063179371724065',\n",
    "       'WCIO Cause of Injury Code_0.020797632029911202',\n",
    "       'WCIO Cause of Injury Code_0.021285096161094332',\n",
    "       'WCIO Cause of Injury Code_0.021574056857414228',\n",
    "       'WCIO Cause of Injury Code_0.025199885420802155',\n",
    "       'WCIO Cause of Injury Code_0.026026564282447772',\n",
    "       'WCIO Cause of Injury Code_0.02911467468050998',\n",
    "       'WCIO Cause of Injury Code_0.03150927940740443',\n",
    "       'WCIO Cause of Injury Code_0.03918558312268517',\n",
    "       'WCIO Cause of Injury Code_0.04355265868967632',\n",
    "       'WCIO Cause of Injury Code_0.046271401936790475',\n",
    "       'WCIO Cause of Injury Code_0.05060832508329606',\n",
    "       'WCIO Cause of Injury Code_0.05538999643196357',\n",
    "       'WCIO Cause of Injury Code_0.05777706305373664',\n",
    "       'WCIO Cause of Injury Code_0.06496338993612712',\n",
    "       'WCIO Cause of Injury Code_0.10859142967701732',\n",
    "       'WCIO Nature of Injury Code_7.53810512138862e-06',\n",
    "       'WCIO Nature of Injury Code_2.261431536416586e-05',\n",
    "       'WCIO Nature of Injury Code_5.5279437556849874e-05',\n",
    "       'WCIO Nature of Injury Code_5.7792139263979416e-05',\n",
    "       'WCIO Nature of Injury Code_0.00010553347169944068',\n",
    "       'WCIO Nature of Injury Code_0.00014071129559925424',\n",
    "       'WCIO Nature of Injury Code_0.00014573669901351332',\n",
    "       'WCIO Nature of Injury Code_0.00017840182120619732',\n",
    "       'WCIO Nature of Injury Code_0.0002789098894913789',\n",
    "       'WCIO Nature of Injury Code_0.00030654960826980386',\n",
    "       'WCIO Nature of Injury Code_0.00031660041509832203',\n",
    "       'WCIO Nature of Injury Code_0.000344240133876747',\n",
    "       'WCIO Nature of Injury Code_0.0004723879209403535',\n",
    "       'WCIO Nature of Injury Code_0.0005000276397187784',\n",
    "       'WCIO Nature of Injury Code_0.0006080738131253486',\n",
    "       'WCIO Nature of Injury Code_0.0006130992165396077',\n",
    "       'WCIO Nature of Injury Code_0.0006960183728748825',\n",
    "       'WCIO Nature of Injury Code_0.0007437597053103437',\n",
    "       'WCIO Nature of Injury Code_0.000753810512138862',\n",
    "       'WCIO Nature of Injury Code_0.0008216534582313595',\n",
    "       'WCIO Nature of Injury Code_0.001075436330651443',\n",
    "       'WCIO Nature of Injury Code_0.0012010714160079201',\n",
    "       'WCIO Nature of Injury Code_0.001289015975757454',\n",
    "       'WCIO Nature of Injury Code_0.0015503369532989262',\n",
    "       'WCIO Nature of Injury Code_0.0015980782857343873',\n",
    "       'WCIO Nature of Injury Code_0.001861911964982989',\n",
    "       'WCIO Nature of Injury Code_0.002085542416917518',\n",
    "       'WCIO Nature of Injury Code_0.0022237410108096427',\n",
    "       'WCIO Nature of Injury Code_0.002583057354929167',\n",
    "       'WCIO Nature of Injury Code_0.0027715099829638823',\n",
    "       'WCIO Nature of Injury Code_0.003336867867068029',\n",
    "       'WCIO Nature of Injury Code_0.003374558392674972',\n",
    "       'WCIO Nature of Injury Code_0.004688701385503721',\n",
    "       'WCIO Nature of Injury Code_0.0048671032067099185',\n",
    "       'WCIO Nature of Injury Code_0.004904793732316862',\n",
    "       'WCIO Nature of Injury Code_0.00907085316273764',\n",
    "       'WCIO Nature of Injury Code_0.00950555055807105',\n",
    "       'WCIO Nature of Injury Code_0.009910095532918906',\n",
    "       'WCIO Nature of Injury Code_0.010498067732387217',\n",
    "       'WCIO Nature of Injury Code_0.012960515405374167',\n",
    "       'WCIO Nature of Injury Code_0.013086150490730643',\n",
    "       'WCIO Nature of Injury Code_0.021719793556427742',\n",
    "       'WCIO Nature of Injury Code_0.021978601832262086',\n",
    "       'WCIO Nature of Injury Code_0.030775570508922604',\n",
    "       'WCIO Nature of Injury Code_0.03970319967435386',\n",
    "       'WCIO Nature of Injury Code_0.04484670006884803',\n",
    "       'WCIO Nature of Injury Code_0.06264919166386082',\n",
    "       'WCIO Nature of Injury Code_0.08253220027237687',\n",
    "       'WCIO Nature of Injury Code_0.09660081713059517',\n",
    "       'WCIO Nature of Injury Code_0.19327952801411133',\n",
    "       'WCIO Nature of Injury Code_0.294254958816819',\n",
    "       'WCIO Part Of Body Code_0.00014573669901351332',\n",
    "       'WCIO Part Of Body Code_0.0002537828724200835',\n",
    "       'WCIO Part Of Body Code_0.0006658659523893281',\n",
    "       'WCIO Part Of Body Code_0.000693505671167753',\n",
    "       'WCIO Part Of Body Code_0.0008141153531099709',\n",
    "       'WCIO Part Of Body Code_0.0010879998391870908',\n",
    "       'WCIO Part Of Body Code_0.0012789651689289357',\n",
    "       'WCIO Part Of Body Code_0.0013945494474568946',\n",
    "       'WCIO Part Of Body Code_0.0017890436154762324',\n",
    "       'WCIO Part Of Body Code_0.0020051359622893727',\n",
    "       'WCIO Part Of Body Code_0.0021483599595957564',\n",
    "       'WCIO Part Of Body Code_0.002326761780801954',\n",
    "       'WCIO Part Of Body Code_0.0028041751051565665',\n",
    "       'WCIO Part Of Body Code_0.0030328309605053548',\n",
    "       'WCIO Part Of Body Code_0.003193643869761645',\n",
    "       'WCIO Part Of Body Code_0.0032690249209755312',\n",
    "       'WCIO Part Of Body Code_0.0034147616199890446',\n",
    "       'WCIO Part Of Body Code_0.0034851172677886717',\n",
    "       'WCIO Part Of Body Code_0.003517782389981356',\n",
    "       'WCIO Part Of Body Code_0.0036057269497308895',\n",
    "       'WCIO Part Of Body Code_0.004495223354054747',\n",
    "       'WCIO Part Of Body Code_0.00453291387966169',\n",
    "       'WCIO Part Of Body Code_0.004633421947946872',\n",
    "       'WCIO Part Of Body Code_0.004952535064752323',\n",
    "       'WCIO Part Of Body Code_0.006615943594872079',\n",
    "       'WCIO Part Of Body Code_0.006734040575107167',\n",
    "       'WCIO Part Of Body Code_0.006779269205835498',\n",
    "       'WCIO Part Of Body Code_0.007364728703596681',\n",
    "       'WCIO Part Of Body Code_0.009181412037851338',\n",
    "       'WCIO Part Of Body Code_0.010236746754845745',\n",
    "       'WCIO Part Of Body Code_0.010714160079200358',\n",
    "       'WCIO Part Of Body Code_0.011302132278668671',\n",
    "       'WCIO Part Of Body Code_0.011782058304730413',\n",
    "       'WCIO Part Of Body Code_0.013196709365844344',\n",
    "       'WCIO Part Of Body Code_0.013638944866299142',\n",
    "       'WCIO Part Of Body Code_0.014028413630904221',\n",
    "       'WCIO Part Of Body Code_0.014443009412580594',\n",
    "       'WCIO Part Of Body Code_0.01735774339285086',\n",
    "       'WCIO Part Of Body Code_0.018968385187120896',\n",
    "       'WCIO Part Of Body Code_0.0196066114207318',\n",
    "       'WCIO Part Of Body Code_0.020335294915799367',\n",
    "       'WCIO Part Of Body Code_0.021976089130554956',\n",
    "       'WCIO Part Of Body Code_0.02261682806587299',\n",
    "       'WCIO Part Of Body Code_0.02413701259868636',\n",
    "       'WCIO Part Of Body Code_0.024436024101834774',\n",
    "       'WCIO Part Of Body Code_0.02686580665262904',\n",
    "       'WCIO Part Of Body Code_0.03257215222952022',\n",
    "       'WCIO Part Of Body Code_0.032612355456834295',\n",
    "       'WCIO Part Of Body Code_0.043318977430913265',\n",
    "       'WCIO Part Of Body Code_0.05513621355954349',\n",
    "       'WCIO Part Of Body Code_0.06318690982918654',\n",
    "       'WCIO Part Of Body Code_0.06550110810145285',\n",
    "       'WCIO Part Of Body Code_0.08356994607742137',\n",
    "       'WCIO Part Of Body Code_0.0895526888420968',\n",
    "       'WCIO Part Of Body Code_0.14260335998472276'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in X_train_encoded:\n",
    "    v = cramers_v(X_train_encoded[var], Y_train_encoded)\n",
    "    print(f\"{var}: Cramér's V = {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorted Results to understand what features have a greater Cramér's V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for var in X_train_encoded:\n",
    "    v = cramers_v(X_train_encoded[var], Y_train_encoded)\n",
    "    results.append((var, v))\n",
    "\n",
    "results_sorted = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for var, v in results_sorted:\n",
    "    print(f\"{var}: Cramér's V = {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features to Discard based on Cramér's V (<0.1):\n",
    "\n",
    "- County of Injury\n",
    "- District Name\n",
    "- Medical Fee Region\n",
    "- zip_code_cat\n",
    "- Season_of_Accident\n",
    "- Age_Group\n",
    "- Alternative Dispute Resolution\n",
    "- COVID-19 Indicator (Cramér's V = 0.0996)\n",
    "- Gender (Cramér's V = 0.0908)\n",
    "- **WCIO Nature of Injury** (cat)\n",
    "\n",
    "Best Features based on Cramér's V (>0.3):\n",
    "- Attorney/Representative: Cramér's V = 0.6078\n",
    "- First Hearing Date Binary: Cramér's V = 0.5337\n",
    "- C-2 Date Bin: Cramér's V = 0.4916\n",
    "- C-3 Date Bin: Cramér's V = 0.4689"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"mi\">\n",
    "\n",
    "### 9.1.4 Mutual Information\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Mutual Information\n",
    "mi = mutual_info_classif(X_train_encoded, Y_train_encoded)\n",
    "\n",
    "for var, score in zip(X_train_encoded.columns, mi):\n",
    "    print(f\"{var}: MI = {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_mi = []\n",
    "\n",
    "# for var in X_train_encoded:\n",
    "#     mi = mutual_info_classif(X_train_encoded, Y_train_encoded)\n",
    "#     results_mi.append((var, v))\n",
    "\n",
    "# results_sorted_mi = sorted(results_mi, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# for var, v in results_sorted_mi:\n",
    "#     print(f\"{var}: MI = {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features to Discard based on Mutual Information (<0.01):\n",
    "- County of Injury\n",
    "- District Name (NY = 0.0228)\n",
    "- Medical Fee Region (IV = 0.0242)\n",
    "- zip_code_cat (1 = 0.0369)\n",
    "- Season_of_Accident\n",
    "- Age_Group\n",
    "- Alternative Dispute Resolution\n",
    "- COVID-19 Indicator\n",
    "- WCIO Nature of Injury Code (cat)\n",
    "   \n",
    "    WCIO Nature of Injury Code_cat_Occupational Disease or Cumulative Injury: MI = 0.0000\n",
    "\n",
    "    WCIO Nature of Injury Code_cat_Specific Injury: MI = 0.0249"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"rf\">\n",
    "\n",
    "### 9.1.5 Random Forest\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_model.fit(X_train_encoded, Y_train_encoded)\n",
    "\n",
    "# Features importance\n",
    "feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# DF to display the results\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': X_train_encoded.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display important features\n",
    "print(feature_importances_df)\n",
    "\n",
    "# Selecting features with importance above a threshold\n",
    "#threshold = 0.01  \n",
    "#selected_features = feature_importances_df[feature_importances_df['Importance'] > threshold]\n",
    "\n",
    "#print(\"\\nSelected Features:\")\n",
    "#print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest\n",
    "\n",
    "Features to Discard based on Importance (<0.005):\n",
    "\n",
    "- Alternative Dispute Resolution\n",
    "- County of Injury\n",
    "- COVID-19 Indicator\n",
    "- zip_code_cat\n",
    "- WCIO Nature of Injury Code_cat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"dt\">\n",
    "\n",
    "### 9.1.6 Decision Tree\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Decision Tree Classifier\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train_encoded, Y_train_encoded)\n",
    "\n",
    "# Obter importância das features\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Criar um DataFrame para visualizar os resultados\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train_encoded.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Selecionar as features acima de um limiar de importância (exemplo: 0.1)\n",
    "threshold = 0.1\n",
    "selected_features = feature_importance_df[feature_importance_df['Importance'] > threshold]['Feature']\n",
    "print(\"\\nSelected Features:\")\n",
    "print(selected_features.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees\n",
    "\n",
    "Features to Discard based on Importance (<0.005):\n",
    "\n",
    "- Alternative Dispute Resolution\n",
    "- County of Injury\n",
    "- COVID-19 Indicator\n",
    "- District Name\n",
    "- Medical Fee Region\n",
    "- zip_code_cat\n",
    "- Age_Group\n",
    "- WCIO Nature of Injury Code_cat\n",
    "- WCIO Cause of Injury_cat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cb\">\n",
    "\n",
    "### 9.1.7 Catboost\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Train a CatBoost model\n",
    "catboost_model = CatBoostClassifier(random_state=42, verbose=0)\n",
    "catboost_model.fit(X_train_encoded, Y_train_encoded)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = catboost_model.get_feature_importance()\n",
    "\n",
    "# Create a DataFrame to view the results\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': X_train_encoded.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display top features\n",
    "print(feature_importances_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost\n",
    "\n",
    "Features to Discard based on Importance (<1.0):\n",
    "\n",
    "- Alternative Dispute Resolution\n",
    "- County of Injury\n",
    "- Medical Fee Region\n",
    "- zip_code_cat\n",
    "- WCIO Nature of Injury Code_cat\n",
    "  \n",
    "  -------------------------------\n",
    "- **WCIO Cause of Injury_cat**\n",
    "- **Age_Group**\n",
    "- **Season_of_Accident**\n",
    "- **COVID-19 Indicator**\n",
    "\n",
    "** - Consider if threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some ideas:**\n",
    "\n",
    "Keep (almost for sure):\n",
    "\n",
    "-  Attorney/Representative_1\n",
    "-  C-2 Date Bin_1\n",
    "-  C-3 Date Bin_1\n",
    "-  First Hearing Date Binary_1\n",
    "  \n",
    "\n",
    "\n",
    "Discard (almost sure):\n",
    "\n",
    "- County of Injury\n",
    "- zip_code_cat ('zip_code_cat_4', 'zip_code_cat_5', 'zip_code_cat_6','zip_code_cat_7', 'zip_code_cat_8', 'zip_code_cat_9')\n",
    "- Medical Fee Region ('Medical Fee Region_II','Medical Fee Region_III')\n",
    "- Carrier Type ('Carrier Type_5C. SPECIAL FUND - POI CARRIER WCB MENANDS', 'Carrier Type_5D. SPECIAL FUND - UNKNOWN',)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"wrapper\">\n",
    "\n",
    "### 9.2 Wrapper Methods\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"rfe\">\n",
    "\n",
    "#### 9.2.1 RFE\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(estimator=model1, n_features_to_select=3)     #Try another values and see their scores\n",
    "rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std_scaler_num = X_train_std_scaler[metric_features]\n",
    "X_val_std_scaler_num = X_val_std_scaler[metric_features]\n",
    "\n",
    "X_train_std_scaler_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rfe = rfe.fit_transform(X_train_std_scaler_num, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = pd.Series(rfe.support_, index = X_train_std_scaler_num.columns)         #If it says True we should keep that feature\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the optimum value for the number of features selected, to get the higher score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nº of features\n",
    "nof_list=np.arange(1,7)            \n",
    "high_score=0\n",
    "#Variable to store the optimum features\n",
    "nof=0           \n",
    "train_score_list =[]\n",
    "val_score_list = []\n",
    "\n",
    "for n in range(len(nof_list)):\n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    rfe = RFE(estimator = model,n_features_to_select = nof_list[n])\n",
    "    \n",
    "    X_train_rfe = rfe.fit_transform(X_train_std_scaler_num,y_train)\n",
    "    X_val_rfe = rfe.transform(X_val_std_scaler_num)\n",
    "    \n",
    "    model.fit(X_train_rfe,y_train)\n",
    "    \n",
    "    #storing results on training data\n",
    "    train_score = model.score(X_train_rfe,y_train)\n",
    "    train_score_list.append(train_score)\n",
    "   \n",
    "    #storing results on training data\n",
    "    val_score = model.score(X_val_rfe,y_val)\n",
    "    val_score_list.append(val_score)\n",
    "    \n",
    "    #check best score\n",
    "    if(val_score >= high_score):\n",
    "        high_score = val_score\n",
    "        nof = nof_list[n]\n",
    "\n",
    "        #adding mention of variables to keep\n",
    "        features_to_select = pd.Series(rfe.support_, index = X_train_std_scaler_num.columns)\n",
    "        \n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))\n",
    "print(f\"Features to select: \\n{features_to_select}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the Recursive feature elimination with cross-validation method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "rfe_cv = RFECV(estimator=model, step=2, cv=7, scoring='accuracy')\n",
    "rfe_cv.fit(X_train_std_scaler_num, y_train)\n",
    "print(\"Optimal number of features:\", rfe_cv.n_features_)\n",
    "print(\"Best cross-validated score:\", rfe_cv.score(X_val_std_scaler_num, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(1,7)), train_score_list, label=\"Score on Training Set\", color='yellowgreen')\n",
    "plt.plot(list(range(1,7)), val_score_list, label=\"Score on Test Set\", color='dimgray')\n",
    "plt.xlabel(\"Maximum Depth\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using another classifier, to analyse the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no of features\n",
    "nof_list=np.arange(1,7)            \n",
    "high_score=0\n",
    "#Variable to store the optimum features\n",
    "nof=0           \n",
    "train_score_list =[]\n",
    "val_score_list = []\n",
    "for n in range(len(nof_list)):\n",
    "    #call support vector machines classifier\n",
    "    model = RandomForestClassifier(random_state=27)\n",
    "  \n",
    "    #create RFE instance\n",
    "    rfe = RFE(estimator = model,n_features_to_select = nof_list[n])\n",
    "   \n",
    "    X_train_rfe = rfe.fit_transform(X_train_std_scaler_num,y_train)\n",
    "    X_val_rfe = rfe.transform(X_val_std_scaler_num)\n",
    "   \n",
    "    model.fit(X_train_rfe,y_train)\n",
    "  \n",
    "    #storing results on training data\n",
    "    train_score = model.score(X_train_rfe,y_train)\n",
    "    train_score_list.append(train_score)\n",
    "  \n",
    "    #storing results on training data\n",
    "    val_score = model.score(X_val_rfe,y_val)\n",
    "    val_score_list.append(val_score)\n",
    "   \n",
    "    #check best score\n",
    "    if(val_score > high_score):\n",
    "        high_score = val_score\n",
    "        nof = nof_list[n]\n",
    "      \n",
    "        #adding mention of variables to keep\n",
    "        features_to_select = pd.Series(rfe.support_, index = X_train_std_scaler_num.columns)\n",
    "      \n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))\n",
    "print(f\"Features to select: \\n{features_to_select}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(1,7)), train_score_list, label=\"Score on Training Set\", color='yellowgreen')\n",
    "plt.plot(list(range(1,7)), val_score_list, label=\"Score on Test Set\", color='dimgray')\n",
    "plt.xlabel(\"Maximum Depth\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can maybe predict, by this chart, is an overfitting using this model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"embedded\">\n",
    "\n",
    "### 9.3 Embedded Methods\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"lasso\">\n",
    "\n",
    "#### 9.3.1 Lasso Regression\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(coef,name):\n",
    "    imp_coef = coef.sort_values()\n",
    "    plt.figure(figsize=(8,6))\n",
    "    imp_coef.plot(kind = \"barh\")\n",
    "    plt.title(\"Feature importance using \" + name + \" Model\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LassoCV(eps=0.01)      #Depending of the strength of the eps, we can get rid of some variables, TRY 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train_std_scaler_num, Y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(reg.coef_, index=X_train_std_scaler_num.columns)\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(coef.sort_values(),'Lasso')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"select\">\n",
    "\n",
    "### 9.4 Select K Best Method\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SelectKBest with f_regression as the scoring function\n",
    "selector = SelectKBest(score_func=f_regression, k=5)        #Adjust the value of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.fit(X_train_std_scaler_num, Y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.Series(selector.scores_, index=X_train_std_scaler_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance_kbest(scores, name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scores.plot(kind=\"barh\")\n",
    "    plt.title(\"Feature importance using \" + name + \" Method\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance_kbest(scores.sort_values(), 'SelectKBest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Predictor                      | Spearman        | RFE LR   | RFE RandForest | RFECV   | Lasso | SelectKBest | What to do? (One possible way to \"solve\")          |\n",
    "|--------------------------------|-----------------|----------|----------------|---------|-------|-------------|-----------------------------------------------------|\n",
    "| Age at Injury                  | Keep            | Discard  | Keep           | Keep    | Keep?  | Keep?        | Include in the model                                |\n",
    "| Average Weekly Wage            | Keep            | Keep     | Keep           | Keep    | Keep  | Keep        | Include in the model                                |\n",
    "| IME-4 Count                    | Keep            | Discard  | Keep           | Keep    | Keep  | Keep        | Include in the model                                |\n",
    "| Number of Dependents           | Discard         | Discard  | Keep           | Keep    | Discard| Discard     | Discard in the model                                |\n",
    "| Days Between Accident_Assembly | Either this or Accident_C2 | Keep | Keep | Keep | Discard | Discard | Include in the model??                              |\n",
    "| Days Between Accident_C2       | Either this or Accident_Assembly | Keep | Keep | Keep | Discard | Discard | Discard in the model??                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Categorical Data\n",
    "\n",
    "| Predictor                      | Chi-Square | Cramér's V | Mutual Information | Decision Tree | Random Forest | CatBoost |\n",
    "|--------------------------------|------------|------------|--------------------|---------------|---------------|--------------|\n",
    "| Industry Code                  | Keep       |            |                    |               |                   |          |   \n",
    "| WCIO Cause of Injury Code      | Keep       |            |                    |               |               |          |\n",
    "| WCIO Nature of Injury Code     | Keep       |            |                    |               |               |          |\n",
    "| WCIO Part Of Body Code         | Keep       |            |                     |               |               |          |\n",
    "| Alternative Dispute Resolution | Keep       | Discard    | Discard            | Discard             | Discard              |  Discard         |\n",
    "| Attorney/Representative        | Keep       | Keep(+)    | Keep               |   Keep               | Keep               |  Keep         |\n",
    "| Carrier Type                   | Keep       | Keep       | Keep               |  Keep                |  Keep              |  Keep         |\n",
    "| County of Injury               | Keep       | Discard    | Discard            | Discard               | Discard              | Discard          |\n",
    "| COVID-19 Indicator             | Keep       | Discard(?) | Discard            | Discard              | Discard              |          | \n",
    "| District Name                  | Keep       | Discard    | Discard(?)         | Discard              | Keep               | Keep          |  \n",
    "| Gender                         | Keep       | Discard(?) | Keep               | Keep                 | Keep               | Keep          |\n",
    "| Industry Code Description      | Keep       | Keep       | Keep               |  Keep                | Keep               | Keep          |   \n",
    "| Medical Fee Region             | Keep       | Discard    | Discard(?)         | Discard               | Keep               | Discard          |\n",
    "| zip_code_cat                   | Keep       | Discard    | Discard(?)         |Discard              |  Discard             |  Discard         |\n",
    "| First Hearing Date Binary      | Keep       | Keep(+)    | Keep               |Keep                  | Keep               | Keep          |\n",
    "| C-2 Date Bin                   | Keep       | Keep(+)    | Keep               |Keep                  | Keep               | Keep          | \n",
    "| C-3 Date Bin                   | Keep       | Keep(+)    | Keep               | Keep                 | Keep               |Keep           |\n",
    "| Season_of_Accident             | Keep       | Discard    | Discard            | Keep                 | Keep               |          |\n",
    "| Age_Group                      | Keep       | Discard    | Discard            |Discard               | Keep               |          |\n",
    "| WCIO Part of Body_cat          | Keep       | Keep       | Keep               | Keep                 | Keep               | Keep          | \n",
    "| WCIO Nature of Injury Code_cat | Keep       | Keep       | Discard(?)         | Discard              | Keep               |   Discard        |\n",
    "| WCIO Cause of Injury_cat       | Keep       | Keep       | Keep               |Discard               | Discard             |          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"dropfeat\">\n",
    "\n",
    "### 9.5 Drop Features according to Feature Selections\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have checked the performance of our models firsly by deleting Days Between Accident_assembly and later by deleting Days Betweem Accident_C2. Our model performed better without Days Between Accident_C2 so we decided to keep Days Between Accident_Assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std_scaler_encoded.drop(columns=[\"Number of Dependents\", \"Days Between Accident_C2\"], inplace=True)\n",
    "X_val_std_scaler_encoded.drop(columns=[\"Number of Dependents\", \"Days Between Accident_C2\"], inplace=True)\n",
    "X_test_std_scaler_encoded.drop(columns=[\"Number of Dependents\", \"Days Between Accident_C2\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Save Proprocessed Data\n",
    "Saving the target variable back into the preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_encoded_df = pd.concat([X_train_std_scaler_encoded, y_train], axis=1)\n",
    "# train_encoded_df.to_csv(\"train_encoded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_encoded_df = pd.concat([X_val_std_scaler_encoded, y_val], axis=1)\n",
    "# validation_encoded_df.to_csv(\"validation_encoded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_std_scaler_encoded.to_csv(\"test_encoded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_std_scaler_encoded\n",
    "y_train = y_train\n",
    "\n",
    "X_val = X_val_std_scaler_encoded\n",
    "y_val = y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to help display metrics for all models\n",
    "\n",
    "# helper method for score_model - not to be used seperately\n",
    "def print_scores(per_class, y_actual):\n",
    "    for x,y in zip(per_class, np.unique(y_actual)):\n",
    "        print(\"[\"+str(y)+\"]:     \\t\" + str(round(x,2)))\n",
    "\n",
    "# displays the scores for Precision, Recall, and F1\n",
    "def score_model(y_actual, y_predicted, score_train, score_test):\n",
    "    print(\"--------- Accuracy ---------\")\n",
    "    acc_score = accuracy_score(y_actual, y_predicted)\n",
    "    print(\"Accuracy Score: \" + str(acc_score))\n",
    "\n",
    "    print(\"--------- Precision ---------\")\n",
    "    precision_per_class = precision_score(y_actual, y_predicted, average=None)\n",
    "    print_scores(precision_per_class, y_actual)\n",
    "    precision_weighted = precision_score(y_actual, y_predicted, average='macro')\n",
    "    print(\"\\nMacro precision: \" + str(round(precision_weighted, 3)) + \"\\n\")\n",
    "\n",
    "    print(\"---------- Recall ----------\")\n",
    "    recall_per_class = recall_score(y_actual, y_predicted, average=None)\n",
    "    print_scores(recall_per_class, y_actual)\n",
    "    recall_per_weighted = recall_score(y_actual, y_predicted, average='macro')\n",
    "    print(\"\\nMacro recall: \" + str(round(recall_per_weighted, 3)) + \"\\n\")\n",
    "\n",
    "    print(\"------------ F1 ------------\")\n",
    "    f1_per_class = f1_score(y_actual, y_predicted, average=None)\n",
    "    print_scores(f1_per_class, y_actual)\n",
    "    f1_per_weighted = f1_score(y_actual, y_predicted, average='macro')\n",
    "    print(\"\\nMacro f1: \" + str(round(f1_per_weighted, 3)) + \"\\n\")\n",
    "\n",
    "    print(\"------ Individual Score Comparisons ------ \")\n",
    "    print(\"Train Score: \" + str(score_train))\n",
    "    print(\"Test Score: \" + str(score_test))\n",
    "    diff = np.abs(score_train - score_test)\n",
    "    print(\"Difference: \" + str(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', C=10)\n",
    "\n",
    "# Fit the model to the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Determine the scores for the model for both train and validation sets\n",
    "score_train = model.score(X_train, y_train)\n",
    "score_test = model.score(X_val, y_val)\n",
    "\n",
    "# Use the model to predict on the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Display the model metrics using the score_model function\n",
    "score_model(y_val, y_pred, score_train, score_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridsearch - decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Create a DecisionTreeClassifier\n",
    "# dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# # Define the parameter grid to search\n",
    "# param_grid = {\n",
    "#     'criterion': ['gini', 'entropy'],                          # Split criterion\n",
    "#     'splitter': ['best', 'random'],                             # Splitting strategy\n",
    "#     'max_depth': [None, 10, 20, 30],                            # Max depth of the tree\n",
    "#     'min_samples_split': [2, 5, 10],                            # Minimum samples to split an internal node\n",
    "#     'min_samples_leaf': [1, 2, 4],                              # Minimum samples at a leaf node\n",
    "#     'max_features': [None, 'sqrt', 'log2'],                     # Max features to consider for splits\n",
    "#     'max_leaf_nodes': [None, 10, 20, 30],                       # Max number of leaf nodes\n",
    "#     'min_impurity_decrease': [0.0, 0.1, 0.2]                   # Minimum impurity decrease to split\n",
    "# }\n",
    "\n",
    "# # Set up GridSearchCV with 5-fold cross-validation and scoring based on accuracy\n",
    "# grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# # Fit GridSearchCV on the training data\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters and the best score\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)\n",
    "# print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# # You can also access the best model found\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# #Best Parameters: {'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
    "# #Best Score: 0.7769977245887005\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model - Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# from sklearn.tree import plot_tree\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Initialize the Decision Tree Classifier\n",
    "# decision_tree = DecisionTreeClassifier(\n",
    "#     criterion='gini',  # 'gini' for Gini Impurity or 'entropy' for Information Gain\n",
    "#     max_depth=10, \n",
    "#     max_features=None,\n",
    "#     max_leaf_nodes=None, \n",
    "#     min_impurity_decrease= 0.0,\n",
    "#     min_samples_leaf= 1,\n",
    "#     min_samples_split=2,\n",
    "#     splitter='best',  # Maximum depth of the tree (None means no limit)\n",
    "#     random_state=42    # Random seed for reproducibility\n",
    "# )\n",
    "\n",
    "# # Train the model\n",
    "# decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# # Determine the scores for the model for both train and validation sets\n",
    "# score_train = model.score(X_train, y_train)\n",
    "# score_test = model.score(X_val, y_val)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = decision_tree.predict(X_val)\n",
    "\n",
    "# # Display the model metrics using the score_model function\n",
    "# score_model(y_val, y_pred, score_train, score_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search - KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# # Define the parameter grid for KNN\n",
    "# param_grid = {\n",
    "#     'n_neighbors': [3, 5, 10, 15],                 \n",
    "#     'algorithm': ['brute', 'kd_tree'],             \n",
    "#     'metric': ['euclidean', 'manhattan', 'minkowski'], \n",
    "#     'weights': ['uniform', 'distance']             \n",
    "# }\n",
    "\n",
    "# # Set up the GridSearchCV with KNN classifier\n",
    "# grid_search = GridSearchCV(\n",
    "#     KNeighborsClassifier(),\n",
    "#     param_grid,\n",
    "#     cv=5,                                         \n",
    "#     scoring='f1_macro'                                                      \n",
    "# )\n",
    "\n",
    "# # Fit the grid search to the training data\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters and the best score\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)\n",
    "# print(\"Best Score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# # Create the KNN model\n",
    "# # n_neighbors specifies the number of neighbors to use for classification\n",
    "# knn_model = KNeighborsClassifier(n_neighbors=5)  \n",
    "\n",
    "# # Fit the model to the training set\n",
    "# knn_model.fit(X_train, y_train)\n",
    "\n",
    "# # Determine the scores for the model for both train and validation sets\n",
    "# score_train = knn_model.score(X_train, y_train)\n",
    "# score_test = knn_model.score(X_val, y_val)\n",
    "\n",
    "# # Use the model to predict on the validation set\n",
    "# y_pred = knn_model.predict(X_val)\n",
    "\n",
    "# # Display the model metrics using the score_model function\n",
    "# score_model(y_val, y_pred, score_train, score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEURAL NETWORK:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(64,), (64, 32), (128, 64)],  # Different hidden layer architectures\n",
    "    'activation': ['relu', 'tanh'],                     # Activation functions\n",
    "    'solver': ['adam', 'sgd'],                          # Optimizers\n",
    "    'alpha': [0.0001, 0.001, 0.01],                     # L2 regularization (alpha)\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],           # Learning rates\n",
    "}\n",
    "\n",
    "# Create the MLPClassifier model\n",
    "mlp = MLPClassifier(max_iter=200, random_state=42)  # Keeping max_iter constant at 200\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=mlp,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=5,  # 5-fold cross-validation\n",
    "                           scoring='f1_macro',  # Evaluation metric\n",
    "                           verbose=2,           # Display progress logs\n",
    "                           n_jobs=-1)           # Use all available processors\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train_std_scaler_encoded, Y_train_encoded_df)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create the model\n",
    "model = MLPClassifier(hidden_layer_sizes=(64, 32),  # Two hidden layers: 64 and 32 neurons\n",
    "                      activation='relu',           # ReLU activation function\n",
    "                      solver='adam',               # Adam optimizer\n",
    "                      alpha=0.0001,                # Regularization term (L2 penalty)\n",
    "                      learning_rate_init=0.001,    # Initial learning rate\n",
    "                      max_iter=200,                # Maximum number of iterations\n",
    "                      random_state=42)             # For reproducibility\n",
    "\n",
    "# Fit the model to the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Determine the scores for the model for both train and validation sets\n",
    "score_train = model.score(X_train, y_train)  # Accuracy on training data\n",
    "score_test = model.score(X_val, y_val)      # Accuracy on validation data\n",
    "\n",
    "# Use the model to predict on the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Display the model metrics using the score_model function\n",
    "score_model(y_val, y_pred, score_train, score_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
